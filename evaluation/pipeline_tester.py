#!/usr/bin/env python3
"""
RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ë„êµ¬
- ë‹¤ì–‘í•œ RAG íŒŒì´í”„ë¼ì¸ ë¹„êµ (LLM, Intent, RAG, LangGraph)
- ì‘ë‹µ ì‹œê°„ ë° ì†ŒìŠ¤ ë¬¸ì„œ ì¶”ì 
- ê°œë°œ ë° ë””ë²„ê¹…ìš©
"""
import requests
import time
import json
import argparse
from typing import Dict, Any, List
from pathlib import Path
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

BASE_URL = "http://localhost:8000/api/v1"

class PipelineTester:
    def __init__(self, endpoint_type: str = "intent"):
        self.base_url = BASE_URL
        self.results = []
        self.endpoint_type = endpoint_type
        self.endpoint_map = {
            "intent": "/process_with_intent_routing",
            "rag": "/query_rag",
            "langgraph": "/langgraph/langgraph_rag"
        }
        # OpenAI í‰ê°€ê¸° (ì§€ì—° ì´ˆê¸°í™”)
        self.use_openai_eval = False
        self.openai_evaluator = None

    def enable_openai_eval(self):
        """OpenAI í‰ê°€ í™œì„±í™” (config.pyì˜ MODEL_KEY ì‚¬ìš©). ì‹¤íŒ¨ ì‹œ ë¹„í™œì„±í™”."""
        if self.openai_evaluator is not None:
            self.use_openai_eval = True
            return True
        try:
            print("OpenAI í‰ê°€ê¸° ì´ˆê¸°í™” ì¤‘...")
            from evaluation.openai_evaluator import OpenAIAnswerEvaluator
            print("OpenAIAnswerEvaluator import ì„±ê³µ")
            self.openai_evaluator = OpenAIAnswerEvaluator()
            print("OpenAIAnswerEvaluator ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
            self.use_openai_eval = True
            print("OpenAI í‰ê°€ ì‹œìŠ¤í…œì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        except Exception as e:
            print(f"OpenAI í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            self.use_openai_eval = False
            self.openai_evaluator = None
            return False

    def _maybe_eval_with_openai(self, query: str, generated_answer: str) -> dict:
        """OpenAIë¡œ ë‹µë³€ í’ˆì§ˆ í‰ê°€. expected_answerê°€ ìˆìœ¼ë©´ ë¹„êµ í‰ê°€, ì—†ìœ¼ë©´ ì¼ë°˜ í‰ê°€."""
        if not self.use_openai_eval or self.openai_evaluator is None:
            return {}
        
        try:
            # datasetì—ì„œ í•´ë‹¹ queryì˜ expected_answer ì°¾ê¸°
            expected_answer = None
            try:
                from evaluation.test_dataset import dataset
                matched = next((c for c in dataset if c.get("query") == query), None)
                expected_answer = matched.get("expected_answer") if matched else None
            except Exception as e:
                pass

            if expected_answer:
                # expected_answerê°€ ìˆìœ¼ë©´ ë¹„êµ í‰ê°€
                eval_result = self.openai_evaluator.evaluate_answer(
                    query, expected_answer, generated_answer
                )
            else:
                # expected_answerê°€ ì—†ìœ¼ë©´ ì¼ë°˜ í’ˆì§ˆ í‰ê°€
                eval_result = self.openai_evaluator.evaluate_answer_quality_only(
                    query, generated_answer
                )
            
            # í‘œì¤€í™”ëœ í˜•íƒœë¡œ ë¦¬í„´
            return {
                "openai_rating": eval_result.get("overall_rating"),
                "openai_scores": eval_result.get("scores"),
                "openai_explanation": eval_result.get("explanation")
            }
        except Exception as e:
            return {"openai_error": str(e)}
    
    def _print_source_details(self, index: int, source: Dict[str, Any]):
        """ì†ŒìŠ¤ ë¬¸ì„œ ìƒì„¸ ì •ë³´ë¥¼ ì¶œë ¥í•˜ëŠ” í—¬í¼ ë©”ì„œë“œ"""
        if isinstance(source, dict):
            if 'metadata' in source:
                metadata = source.get("metadata", {})
                page_content = source.get('page_content', '')
            else:
                metadata = source
                page_content = ''
        else:
            metadata = {}
            page_content = ''
        
        file_name = metadata.get('file_name', 'Unknown')
        main_category = metadata.get('main_category', 'Unknown')
        sub_category = metadata.get('sub_category', 'Unknown')
        page_number = metadata.get('page_number', 'Unknown')
        chunk_index = metadata.get('chunk_index', 'Unknown')
        
        print(f"  {index}. íŒŒì¼ëª…: {file_name}")
        print(f"     ì¹´í…Œê³ ë¦¬: {main_category}/{sub_category}")
        print(f"     ì²­í¬: {chunk_index}, í˜ì´ì§€: {page_number}")
        if len(page_content) > 0:
            print(f"     ë‚´ìš©: {page_content[:100]}...")

    def check_server(self) -> bool:
        """ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get(f"{self.base_url}/healthcheck", timeout=5)
            return response.status_code == 200
        except Exception:
            return False

    def save_results(self, filename: str):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)
            print(f"ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def test_llm_only(self, prompt: str) -> Dict[str, Any]:
        """LLM ì „ìš© í…ŒìŠ¤íŠ¸"""
        print(f"\nLLM ì „ìš© í…ŒìŠ¤íŠ¸")
        print(f"ì§ˆë¬¸: {prompt}")

        start_time = time.time()
        try:
            response = requests.post(
                f"{self.base_url}/answer_with_llm_only",
                json={"prompt": prompt},
                timeout=300
            )
            end_time = time.time()
            
            if response.status_code == 200:
                data = response.json()
                
                result = {
                    "type": "LLM_ONLY",
                    "question": prompt,
                    "response_time": round(end_time - start_time, 2),
                    "status": data.get("status"),
                    "answer": data.get("response", "")
                }
                
                print(f"ì‘ë‹µ ì‹œê°„: {result['response_time']}ì´ˆ")
                print(f"ë‹µë³€: {result['answer'][:100]}...")
                print("RAG ì—†ì´ LLMë§Œ ì‚¬ìš© (ë¹ ë¥¸ ì‘ë‹µ)")
                
                return result
            else:
                print(f"ì˜¤ë¥˜: {response.status_code}")
                return {"type": "LLM_ONLY", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            print(f"ì˜ˆì™¸: {e}")
            return {"type": "LLM_ONLY", "error": str(e)}

    def test_intent_routing(self, prompt: str) -> Dict[str, Any]:
        """Intent ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸ (/process_with_intent_routing)"""
        print(f"\nIntent ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸")
        print(f"ì§ˆë¬¸: {prompt}")
        start_time = time.time()
        try:
            response = requests.post(
                f"{self.base_url}{self.endpoint_map['intent']}",
                json={"prompt": prompt},
                timeout=300
            )
            elapsed = round(time.time() - start_time, 2)
            
            if response.status_code == 200:
                result = response.json()
                sources = result.get("sources", [])
                category = result.get("category", "unknown")
                
                print(f"ì‘ë‹µ ì‹œê°„: {elapsed}ì´ˆ")
                print(f"ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬: {category}")
                print(f"ì†ŒìŠ¤ ë¬¸ì„œ: {len(sources)}ê°œ")
                print(f"ë‹µë³€: {result.get('response', '')[:200]}...")
                
                if category == "company_products":
                    print("ì²˜ë¦¬ íë¦„: Intent ë¶„ë¥˜ â†’ ìƒí’ˆëª… ì¶”ì¶œ â†’ ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ (íŒŒì¼ëª… â†’ í‚¤ì›Œë“œ â†’ í´ë”)")
                else:
                    print(f"ì²˜ë¦¬ íë¦„: Intent ë¶„ë¥˜ â†’ {category} ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰")
                
                # ì†ŒìŠ¤ ë¬¸ì„œ ìƒì„¸ ì •ë³´ ì¶œë ¥
                if sources:
                    print("ì†ŒìŠ¤ ë¬¸ì„œ ìƒì„¸:")
                    for i, source in enumerate(sources[:3], 1):
                        self._print_source_details(i, source)
                
                eval_payload = self._maybe_eval_with_openai(prompt, result.get('response', ''))

                return {
                    "type": "INTENT_ROUTING",
                    "response_time": elapsed,
                    "response": result.get("response"),
                    "category": category,
                    "sources": sources,
                    "sources_count": len(sources),
                    **({"openai_eval": eval_payload} if eval_payload else {})
                }
            else:
                print(f"ì˜¤ë¥˜: {response.status_code}")
                return {"type": "INTENT_ROUTING", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            print(f"ì˜ˆì™¸: {e}")
            return {"type": "INTENT_ROUTING", "error": str(e)}

    def test_rag_pipeline(self, prompt: str) -> Dict[str, Any]:
        """RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ í˜¸í™˜ì„±ìš©)"""
        return self.test_intent_routing(prompt)

    def test_basic_rag(self, prompt: str) -> Dict[str, Any]:
        """ê¸°ë³¸ RAG í…ŒìŠ¤íŠ¸ (/query_rag)"""
        print(f"\nê¸°ë³¸ RAG í…ŒìŠ¤íŠ¸")
        print(f"ì§ˆë¬¸: {prompt}")
        start_time = time.time()
        try:
            response = requests.post(
                f"{self.base_url}{self.endpoint_map['rag']}",
                json={"prompt": prompt},
                timeout=300
            )
            elapsed = round(time.time() - start_time, 2)
            
            if response.status_code == 200:
                result = response.json()
                sources = result.get("sources", [])
                
                print(f"ì‘ë‹µ ì‹œê°„: {elapsed}ì´ˆ")
                print(f"ì†ŒìŠ¤ ë¬¸ì„œ: {len(sources)}ê°œ")
                print(f"ë‹µë³€: {result.get('response', '')[:200]}...")
                print("ì²˜ë¦¬ íë¦„: LLM ê¸°ë°˜ ìƒí’ˆëª… ì¶”ì¶œ â†’ í‚¤ì›Œë“œ ê²€ìƒ‰ (í´ë°±: ì¼ë°˜ ê²€ìƒ‰)")
                
                # ì†ŒìŠ¤ ë¬¸ì„œ ìƒì„¸ ì •ë³´ ì¶œë ¥
                if sources:
                    print("ì†ŒìŠ¤ ë¬¸ì„œ ìƒì„¸:")
                    for i, source in enumerate(sources[:3], 1):
                        self._print_source_details(i, source)
                
                eval_payload = self._maybe_eval_with_openai(prompt, result.get('response', ''))

                return {
                    "type": "BASIC_RAG",
                    "response_time": elapsed,
                    "response": result.get("response"),
                    "sources": sources,
                    "sources_count": len(sources),
                    **({"openai_eval": eval_payload} if eval_payload else {})
                }
            else:
                print(f"ì˜¤ë¥˜: {response.status_code}")
                return {"type": "BASIC_RAG", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            print(f"ì˜ˆì™¸: {e}")
            return {"type": "BASIC_RAG", "error": str(e)}
    
    def test_langgraph_rag(self, prompt: str) -> Dict[str, Any]:
        """LangGraph RAG í…ŒìŠ¤íŠ¸"""
        print(f"\nLangGraph RAG í…ŒìŠ¤íŠ¸")
        print(f"ì§ˆë¬¸: {prompt}")

        start_time = time.time()
        try:
            response = requests.post(
                f"{self.base_url}/langgraph/langgraph_rag",
                json={"prompt": prompt},
                timeout=300
            )
            elapsed = round(time.time() - start_time, 2)
            
            if response.status_code == 200:
                result = response.json()
                sources = result.get("sources", [])
                category = result.get("category", "unknown")
                
                print(f"ì›Œí¬í”Œë¡œìš° íƒ€ì…: {result.get('workflow_type', 'langgraph')}")
                print(f"ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬: {category}")
                print(f"ì‘ë‹µ ì‹œê°„: {elapsed}ì´ˆ")
                print(f"ì†ŒìŠ¤ ë¬¸ì„œ: {len(sources)}ê°œ")
                print(f"ë‹µë³€: {result.get('response', '')[:200]}...")
                print("ì²˜ë¦¬ íë¦„: ê·¸ë˜í”„ ê¸°ë°˜ ë…¸ë“œ ì‹¤í–‰: classify_intent â†’ search_documents â†’ filter_relevance â†’ generate_response")
                
                # ì†ŒìŠ¤ ë¬¸ì„œ ìƒì„¸ ì •ë³´ ì¶œë ¥
                if sources:
                    print("ì†ŒìŠ¤ ë¬¸ì„œ ìƒì„¸:")
                    for i, source in enumerate(sources[:3], 1):
                        self._print_source_details(i, source)
                
                eval_payload = self._maybe_eval_with_openai(prompt, result.get('response', ''))

                return {
                    "type": "LANGGRAPH_RAG",
                    "response_time": elapsed,
                    "response": result.get("response"),
                    "category": category,
                    "sources": sources,
                    "sources_count": len(sources),
                    **({"openai_eval": eval_payload} if eval_payload else {})
                }
            else:
                print(f"ì˜¤ë¥˜: {response.status_code}")
                return {"type": "LANGGRAPH_RAG", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            print(f"ì˜ˆì™¸: {e}")
            return {"type": "LANGGRAPH_RAG", "error": str(e)}
    
    def run_comprehensive_test(self, questions: List[str]):
        """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"RAG ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"ì‚¬ìš© ì—”ë“œí¬ì¸íŠ¸: {self.endpoint_map.get(self.endpoint_type)} ({self.endpoint_type})")
        print("=" * 60)
        
        if not self.check_server():
            print("ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.")
            return
        
        print("ì„œë²„ ì—°ê²° í™•ì¸ë¨")
        
        for i, question in enumerate(questions, 1):
            print(f"\ní…ŒìŠ¤íŠ¸ {i}/{len(questions)}")
            print("-" * 40)
            
            # endpoint_typeì— ë”°ë¼ ì ì ˆí•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            if self.endpoint_type == "langgraph":
                result = self.test_langgraph_rag(question)
                test_result = {
                    "question": question,
                    "langgraph_rag": result
                }
            elif self.endpoint_type == "intent":
                result = self.test_intent_routing(question)
                test_result = {
                    "question": question,
                    "intent_routing": result
                }
            elif self.endpoint_type == "rag":
                result = self.test_basic_rag(question)
                test_result = {
                    "question": question,
                    "basic_rag": result
                }
            else:
                # ê¸°ë³¸ê°’: intent routing
                result = self.test_intent_routing(question)
                test_result = {
                    "question": question,
                    "intent_routing": result
                }
            
            self.results.append(test_result)
            
            # ì ì‹œ ëŒ€ê¸°
            time.sleep(1)
        
        self.print_summary()
    
    def print_summary(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½"""
        print(f"\n{'='*60}")
        print("RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print(f"ì‚¬ìš©ëœ ì—”ë“œí¬ì¸íŠ¸: {self.endpoint_type}")
        print(f"{'='*60}")
        
        for i, result in enumerate(self.results, 1):
            print(f"\nì§ˆë¬¸ {i}: {result['question'][:50]}...")
            print("-" * 40)
            
            # ì„ íƒëœ ì—”ë“œí¬ì¸íŠ¸ì— ë”°ë¼ ê²°ê³¼ ì¶œë ¥
            if self.endpoint_type == "langgraph" and 'langgraph_rag' in result:
                langgraph = result['langgraph_rag']
                if 'error' not in langgraph:
                    category = langgraph.get('category', 'Unknown')
                    sources_count = langgraph.get('sources_count', 0)
                    print(f"LangGraph RAG: {langgraph['response_time']}ì´ˆ "
                          f"({category}, ì†ŒìŠ¤: {sources_count}ê°œ, ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš°)")
                else:
                    print(f"LangGraph RAG: ì˜¤ë¥˜ - {langgraph['error']}")
            elif self.endpoint_type == "intent" and 'intent_routing' in result:
                intent = result['intent_routing']
                if 'error' not in intent:
                    category = intent.get('category', 'Unknown')
                    sources_count = intent.get('sources_count', 0)
                    print(f"Intent Routing: {intent['response_time']}ì´ˆ "
                          f"({category}, ì†ŒìŠ¤: {sources_count}ê°œ)")
                else:
                    print(f"Intent Routing: ì˜¤ë¥˜ - {intent['error']}")
            elif self.endpoint_type == "rag" and 'basic_rag' in result:
                rag = result['basic_rag']
                if 'error' not in rag:
                    sources_count = rag.get('sources_count', 0)
                    print(f"Basic RAG: {rag['response_time']}ì´ˆ "
                          f"(ì†ŒìŠ¤: {sources_count}ê°œ)")
                else:
                    print(f"Basic RAG: ì˜¤ë¥˜ - {rag['error']}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ëŒ€í™”í˜• ë©”ë‰´"""
    import argparse
    
    parser = argparse.ArgumentParser(description="RAG ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ë„êµ¬")
    parser.add_argument("--quick-test", action="store_true", help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (langgraph ì—”ë“œí¬ì¸íŠ¸)")
    parser.add_argument("--endpoint", choices=["intent", "rag", "langgraph"], default="langgraph", help="ì‚¬ìš©í•  ì—”ë“œí¬ì¸íŠ¸")
    args = parser.parse_args()
    
    print("RAG ì‹œìŠ¤í…œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ë„êµ¬")
    print("=" * 50)
    
    # --quick-test ì˜µì…˜ì´ ìˆìœ¼ë©´ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if args.quick_test:
        print(f"ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì—”ë“œí¬ì¸íŠ¸: {args.endpoint})")
        tester = PipelineTester(args.endpoint)
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
        test_cases = [
            "KB 4ëŒ€ì—°ê¸ˆ ì‹ ìš©ëŒ€ì¶œì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            "ëŒ€ì¶œ ê¸ˆë¦¬ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì‹ ìš©ëŒ€ì¶œ ì¡°ê±´ì´ ë­”ê°€ìš”?"
        ]
        
        for i, query in enumerate(test_cases, 1):
            print(f"\ní…ŒìŠ¤íŠ¸ {i}/{len(test_cases)}: {query}")
            print("-" * 30)
            
            if args.endpoint == "langgraph":
                result = tester.test_langgraph_rag(query)
            elif args.endpoint == "intent":
                result = tester.test_intent_routing(query)
            elif args.endpoint == "rag":
                result = tester.test_basic_rag(query)
            
            tester.results.append({
                "question": query,
                "result": result
            })
        
        tester.print_summary()
        return
    
    # ì—”ë“œí¬ì¸íŠ¸ ì„ íƒ
    print("í…ŒìŠ¤íŠ¸í•  ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. process_with_intent_routing (Intent ë¼ìš°íŒ…)")
    print("2. query_rag (ê¸°ë³¸ RAG)")
    print("3. langgraph/langgraph_rag (LangGraph V2)")
    print("=" * 50)
    
    endpoint_choice = input("ì—”ë“œí¬ì¸íŠ¸ ì„ íƒ (1-3): ").strip()
    
    if endpoint_choice == "1":
        endpoint_type = "intent"
        endpoint_name = "process_with_intent_routing"
    elif endpoint_choice == "2":
        endpoint_type = "rag"
        endpoint_name = "query_rag"
    elif endpoint_choice == "3":
        endpoint_type = "langgraph"
        endpoint_name = "langgraph/langgraph_rag"
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ê°’(Intent ë¼ìš°íŒ…)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        endpoint_type = "intent"
        endpoint_name = "process_with_intent_routing"
    
    print(f"ì„ íƒëœ ì—”ë“œí¬ì¸íŠ¸: {endpoint_name}")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸ ìœ í˜• ì„ íƒ
    print("í…ŒìŠ¤íŠ¸ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (3ê°œ ì§ˆë¬¸)")
    print("2. ì¹´í…Œê³ ë¦¬ë³„ í…ŒìŠ¤íŠ¸")
    print("3. ë‚œì´ë„ë³„ í…ŒìŠ¤íŠ¸")
    print("4. ì§ì ‘ ì§ˆë¬¸ ì…ë ¥")
    print("5. íŒŒì¼ì—ì„œ ì§ˆë¬¸ ì½ê¸°")
    print("6. ëŒ€ëŸ‰ í…ŒìŠ¤íŠ¸ (10ê°œ ì´ìƒ)")
    print("=" * 50)
    
    choice = input("í…ŒìŠ¤íŠ¸ ìœ í˜• ì„ íƒ (1-6): ").strip()
    
    tester = PipelineTester(endpoint_type)
    
    # OpenAI í‰ê°€ ì‚¬ìš© ì—¬ë¶€ ì„ íƒ
    print("\nOpenAI í‰ê°€ë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (config.pyì˜ MODEL_KEY ì‚¬ìš©)")
    print("1. ì˜ˆ (ì •ë‹µê³¼ ëŒ€ë‹µ ë¹„êµí•˜ì—¬ Good/Normal/Bad ì ìˆ˜ ì¶œë ¥)")
    print("2. ì•„ë‹ˆì˜¤ (í‰ê°€ ì—†ì´ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰)")
    eval_choice = input("ì„ íƒ (1-2): ").strip()
    
    if eval_choice == "1":
        if tester.enable_openai_eval():
            print("OpenAI í‰ê°€ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("OpenAI í‰ê°€ í™œì„±í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í‰ê°€ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.")
    else:
        print("í‰ê°€ ì—†ì´ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.")
    
    # ì„œë²„ ìƒíƒœ í™•ì¸
    if not tester.check_server():
        print("ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”:")
        print("python run_server.py")
        return
    
    # ì§ˆë¬¸ ëª©ë¡ ì¤€ë¹„
    questions = []
    
    if choice == "4":
        # ì§ì ‘ ì§ˆë¬¸ ì…ë ¥
        question = input("í…ŒìŠ¤íŠ¸í•  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if question:
            questions = [question]
        else:
            print("ì§ˆë¬¸ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
    elif choice == "5":
        # íŒŒì¼ì—ì„œ ì§ˆë¬¸ ì½ê¸°
        file_path = input("ì§ˆë¬¸ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                questions = [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return
    else:
        # ë°ì´í„°ì…‹ì—ì„œ ì§ˆë¬¸ ì„ íƒ
        from evaluation.test_dataset import dataset
        
        if choice == "2":
            # ì¹´í…Œê³ ë¦¬ë³„ í…ŒìŠ¤íŠ¸
            print("\nì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
            categories = list(set(case.get("category", "unknown") for case in dataset))
            for i, cat in enumerate(categories, 1):
                print(f"{i}. {cat}")
            
            cat_choice = input("ì¹´í…Œê³ ë¦¬ ì„ íƒ (ë²ˆí˜¸): ").strip()
            try:
                selected_category = categories[int(cat_choice) - 1]
                filtered_cases = [case for case in dataset if case.get("category") == selected_category]
                questions = [case["query"] for case in filtered_cases[:10]]
                print(f"ì„ íƒëœ ì¹´í…Œê³ ë¦¬: {selected_category}")
                print(f"ì§ˆë¬¸ ìˆ˜: {len(questions)}ê°œ")
            except (ValueError, IndexError):
                print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                questions = [case["query"] for case in dataset[:3]]
                
        elif choice == "3":
            # ë‚œì´ë„ë³„ í…ŒìŠ¤íŠ¸
            print("\në‚œì´ë„ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
            print("1. easy (ì‰¬ìš´)")
            print("2. medium (ë³´í†µ)")
            print("3. hard (ì–´ë ¤ìš´)")
            
            diff_choice = input("ë‚œì´ë„ ì„ íƒ (1-3): ").strip()
            difficulty_map = {"1": "easy", "2": "medium", "3": "hard"}
            selected_difficulty = difficulty_map.get(diff_choice, "easy")
            
            filtered_cases = [case for case in dataset if case.get("difficulty") == selected_difficulty]
            questions = [case["query"] for case in filtered_cases[:10]]
            print(f"ì„ íƒëœ ë‚œì´ë„: {selected_difficulty}")
            print(f"ì§ˆë¬¸ ìˆ˜: {len(questions)}ê°œ")
            
        elif choice == "6":
            # ëŒ€ëŸ‰ í…ŒìŠ¤íŠ¸
            num_questions = input("í…ŒìŠ¤íŠ¸í•  ì§ˆë¬¸ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: 10): ").strip()
            try:
                num = int(num_questions) if num_questions else 10
                questions = [case["query"] for case in dataset[:num]]
                print(f"ëŒ€ëŸ‰ í…ŒìŠ¤íŠ¸: {len(questions)}ê°œ ì§ˆë¬¸")
            except ValueError:
                questions = [case["query"] for case in dataset[:10]]
                print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ 10ê°œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        else:
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ (3ê°œ)
            questions = [case["query"] for case in dataset[:3]]
            print(f"ê¸°ë³¸ í…ŒìŠ¤íŠ¸: {len(questions)}ê°œ ì§ˆë¬¸")

    if not questions:
        print("í…ŒìŠ¤íŠ¸í•  ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print(f"{endpoint_type.upper()} íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ì‚¬ìš© ì—”ë“œí¬ì¸íŠ¸: {endpoint_name}")
    print("=" * 60)
    
    for i, question in enumerate(questions, 1):
        print(f"\ní…ŒìŠ¤íŠ¸ {i}/{len(questions)}: {question}")
        print("-" * 40)
        
        if endpoint_type == "intent":
            result = tester.test_intent_routing(question)
        elif endpoint_type == "rag":
            result = tester.test_basic_rag(question)
        elif endpoint_type == "langgraph":
            result = tester.test_langgraph_rag(question)
        else:
            print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì—”ë“œí¬ì¸íŠ¸ íƒ€ì…: {endpoint_type}")
            continue
        
        tester.results.append({
            "question": question,
            "result": result
        })
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        if "error" not in result:
            print(f"ì„±ê³µ: {result.get('response_time', 0)}ì´ˆ")
            if "sources_count" in result:
                print(f"ì†ŒìŠ¤ ë¬¸ì„œ: {result['sources_count']}ê°œ")
            if "category" in result:
                print(f"ì¹´í…Œê³ ë¦¬: {result['category']}")
            
            # OpenAI í‰ê°€ ê²°ê³¼ ì¶œë ¥
            if "openai_eval" in result:
                eval_data = result["openai_eval"]
                if "openai_error" in eval_data:
                    print(f"OpenAI í‰ê°€ ì˜¤ë¥˜: {eval_data['openai_error']}")
                else:
                    rating = eval_data.get("openai_rating", "Unknown")
                    explanation = eval_data.get("openai_explanation", "")
                    
                    # ì ìˆ˜ì— ë”°ë¥¸ ì´ëª¨ì§€ì™€ ìƒ‰ìƒ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
                    rating_lower = rating.lower()
                    if rating_lower == "good":
                        print(f"OpenAI í‰ê°€: ğŸŸ¢ Good - {explanation}")
                    elif rating_lower == "normal":
                        print(f"OpenAI í‰ê°€: ğŸŸ¡ Normal - {explanation}")
                    elif rating_lower == "bad":
                        print(f"OpenAI í‰ê°€: ğŸ”´ Bad - {explanation}")
                    else:
                        print(f"OpenAI í‰ê°€: {rating} - {explanation}")
        else:
            print(f"ì˜¤ë¥˜: {result['error']}")
        
    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ì´ í…ŒìŠ¤íŠ¸: {len(tester.results)}ê°œ")
    
    successful_tests = [r for r in tester.results if "error" not in r["result"]]
    print(f"ì„±ê³µ: {len(successful_tests)}ê°œ")
    print(f"ì‹¤íŒ¨: {len(tester.results) - len(successful_tests)}ê°œ")
    
    if successful_tests:
        avg_time = sum(r["result"].get("response_time", 0) for r in successful_tests) / len(successful_tests)
        print(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        
        # OpenAI í‰ê°€ í†µê³„
        openai_evaluated = [r for r in successful_tests if "openai_eval" in r["result"]]
        if openai_evaluated:
            print(f"\nOpenAI í‰ê°€ í†µê³„ ({len(openai_evaluated)}ê°œ):")
            ratings = [r["result"]["openai_eval"].get("openai_rating", "Unknown").lower() for r in openai_evaluated]
            good_count = ratings.count("good")
            normal_count = ratings.count("normal")
            bad_count = ratings.count("bad")
            
            print(f"ğŸŸ¢ Good: {good_count}ê°œ ({good_count/len(openai_evaluated)*100:.1f}%)")
            print(f"ğŸŸ¡ Normal: {normal_count}ê°œ ({normal_count/len(openai_evaluated)*100:.1f}%)")
            print(f"ğŸ”´ Bad: {bad_count}ê°œ ({bad_count/len(openai_evaluated)*100:.1f}%)")

if __name__ == "__main__":
    main()
