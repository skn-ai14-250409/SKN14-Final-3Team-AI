# Committable non-secret settings.

[runpod]
# OpenAI-compatible endpoint (LM Studio local server)
base_url = "http://localhost:1234/v1"
# Served model id shown by LM Studio (must match exactly)
model = "google/gemma-3-1b:2"

[judge]
# Use LM Studio for judge as well (fully offline)
base_url = "http://localhost:1234/v1"
# Judge model id (can be same as generation)
model = "google/gemma-3-1b:2"

[dataset]
name = "sssssungjae/finance-kb-mixed-dataset-final"
split = "eval"

[eval]
top_k = 2
gen_batch_size = 1
max_workers = 4
out_csv = "ragas_detail.csv"
max_rows = 2

[cost]
# Token cost assumptions for judge LLM (USD per 1M tokens)
judge_in_per_m_usd = 0.15
judge_out_per_m_usd = 0.6
