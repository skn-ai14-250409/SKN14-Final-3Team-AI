목적: 생성/판정 모델과 평가 데이터셋을 바꿀 때 수정해야 할 항목, 파일, 코드 위치를 요약합니다.

모델 변경

- 생성 모델(Generate)
  - 비밀(.env): RUNPOD_API_KEY만 .env에 저장
  - 비밀 아님(settings.toml): runpod.base_url, runpod.model
  - 관련 코드: config.py에서 settings.toml 우선 로드 후, .env가 있으면 .env로 오버라이드
    - runpod.base_url → RUNPOD_BASE_URL
    - runpod.model → RUNPOD_MODEL
  - 유효성 체크: config.py AppConfig.validate()
  - 사용 위치: main.py → GenerationClient(cfg.runpod_base_url, cfg.runpod_api_key, cfg.runpod_model)
  - 메모: OpenAI 호환(vLLM/Runpod 등) 엔드포인트. 예) http://<host>:<port>/v1

- Judge(평가) 모델
  - 비밀(.env): JUDGE_API_KEY 또는 OPENAI_API_KEY
  - 비밀 아님(settings.toml): judge.base_url, judge.model
  - 관련 코드: config.py에서 settings.toml → .env 순서 적용
  - 유효성 체크: AppConfig.validate() (Judge API 키 필수)
  - 사용 위치: main.py → build_judge_llm(cfg.judge_base_url, cfg.judge_api_key, cfg.judge_model)
  - 메모: judge.base_url이 없으면 OpenAI 기본 엔드포인트로 호출

평가 데이터셋 변경

- 비밀 아님(settings.toml): dataset.name, dataset.split
- .env로도 오버라이드 가능: DATASET_NAME, DATASET_SPLIT
  - 관련 코드: config.py에서 settings.toml → .env 순서 적용
  - 로드 위치: main.py에서 load_and_parse_dataset(cfg.dataset_name, cfg.dataset_split)
- 파싱 규칙(data.py)
  - 함수: load_and_parse_dataset(dataset_name, split)
  - 규칙:
    - 단일 컬럼 text가 있으면 Qwen 스타일(user/assistant 블록)에서 질문/정답을 파싱
    - 그렇지 않으면 질문 컬럼(question|query|user_input|q)과 정답 컬럼(ground_truth|reference|answer|a)을 자동 탐색
    - 위 스키마에 맞지 않으면 오류 발생 → 필요한 경우 data.py에 컬럼 매핑 분기 추가
  - 커스텀 스키마 예:
    - 질문 my_q, 정답 my_a 라면: 해당 분기에서 {"_q": row["my_q"], "_gt": row["my_a"]} 형태로 매핑 후 공백 필터 추가

자주 함께 바꾸는 옵션

- settings.toml의 [eval] 섹션: top_k, gen_batch_size, max_workers, out_csv, max_rows
- settings.toml의 [cost] 섹션: judge_in_per_m_usd, judge_out_per_m_usd
- .env로도 오버라이드 가능: TOP_K, GEN_BATCH_SIZE, MAX_WORKERS, OUT_CSV, MAX_ROWS, JUDGE_COST_IN_USD_PER_M, JUDGE_COST_OUT_USD_PER_M

CLI로 1회성 오버라이드(선택)

- 데이터셋만 교체:
  - python -m ragas_eval.main --dataset_name "<hf_user>/<dataset>" --split "eval"
- 기타:
  - --top_k <int> --batch_size <int> --max_workers <int> --max_rows <int> --out_csv <path>

.env 템플릿 예시(비밀만)

# 생성 모델(vLLM/Runpod 등 OpenAI 호환)
RUNPOD_API_KEY=<your_runpod_key>

# Judge 모델(OpenAI 기본)
OPENAI_API_KEY=<your_openai_key>
# 선택: 자체 심사 엔드포인트 사용 시
JUDGE_API_KEY=<your_judge_key>

# 데이터셋
# 데이터셋/파라미터 등 비밀 아님 설정은 settings.toml로 이동

문제 해결 팁

- runpod.base_url 미설정 → config.validate()에서 에러. settings.toml의 runpod.base_url 또는 .env의 RUNPOD_BASE_URL 설정
- Judge API 키 없음 → config.validate()에서 에러. OPENAI_API_KEY 또는 JUDGE_API_KEY 설정
- 데이터셋 스키마 불일치 → data.py의 load_and_parse_dataset에 컬럼 매핑 분기 추가

settings.toml 예시

[runpod]
base_url = "http://<host>:<port>/v1"
model = "qwen3-8b-finance-full"

[judge]
base_url = null
model = "gpt-4o-mini"

[dataset]
name = "sssssungjae/finance-kb-mixed-dataset-final"
split = "eval"

[eval]
top_k = 4
gen_batch_size = 8
max_workers = 6
out_csv = "ragas_detail.csv"
max_rows = -1

[cost]
judge_in_per_m_usd = 0.15
judge_out_per_m_usd = 0.6


RunPod 전환

변경 파일: settings.toml
runpod.base_url: RunPod Pod의 HTTP/Proxy 엔드포인트 + /v1
예: https://<runpod-proxy>/v1 또는 http://<pod-host>:8000/v1
runpod.model: vLLM 실행 시 --served-model-name와 정확히 동일한 이름
비밀(.env)
RUNPOD_API_KEY: RunPod Proxy Token(또는 Pod에서 요구하는 토큰)
Judge를 OpenAI로 쓰면 OPENAI_API_KEY 유지, RunPod로 쓰면 JUDGE_API_KEY에 RunPod 토큰
Judge 구성 선택
OpenAI 사용: settings.toml에서 judge.base_url 제거/null, judge.model은 OpenAI 모델명, .env에 OPENAI_API_KEY
RunPod 사용: judge.base_url을 RunPod /v1, judge.model을 해당 서버의 --served-model-name
vLLM 서버 실행(예시 커맨드)
이미지: ghcr.io/vllm-project/vllm-openai:latest
커맨드: --model <hf_repo> --served-model-name <name> --trust-remote-code
포트: 8000 공개(또는 RunPod Proxy 사용), 비공개 HF면 HUGGING_FACE_HUB_TOKEN 설정
데이터셋 변경

settings.toml의 [dataset]
name = "<HF_USER>/<DATASET>", split = "<train|test|eval|...>"
1회성 오버라이드(선택)
python -m ragas_eval.main --dataset_name "<hf_user>/<ds>" --split "eval"
스키마가 다를 때
data.py: load_and_parse_dataset에 컬럼 매핑 분기 추가가 필요
실행 체크리스트

RunPod로 생성/판정 모두 연결:
settings.toml: runpod.*, judge.*를 RunPod 엔드포인트/모델명으로
.env: RUNPOD_API_KEY(필수), JUDGE_API_KEY(RunPod Judge 시) 또는 OPENAI_API_KEY(OpenAI Judge 시)
실행: 레포 루트에서 python -m ragas_eval.main --max_rows 2
자주 나는 문제
model_not_found: runpod.model/judge.model ≠ --served-model-name
401: .env의 토큰 누락
연결 실패: base_url에 /v1 누락 또는 포트 미오픈
run_local.py 19줄(노란 줄) 이유

원인: run_local.py가 런타임에 sys.path를 수정해 ragas_eval을 임포트합니다. 정적 분석기(IDE)가 이 동적 경로 추가를 모르는 탓에 “Unresolved import”로 표시됩니다.
해소 방법(택1)
레포 루트에서 실행: python -m ragas_eval.main (권장)
VS Code 설정: .vscode/settings.json에 {"python.analysis.extraPaths": [".."]}
또는 프로젝트를 editable 설치로 구성(예: pyproject.toml 추가 후 pip install -e .) — 필요 시 요청 주세요.