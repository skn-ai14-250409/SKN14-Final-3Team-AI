# chat_cli_vllm.py

import os
from openai import OpenAI # ğŸ’¡ openai ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©

# --- 1. vLLM ì„œë²„ ì •ë³´ ì„¤ì • ---
# vLLMì€ OpenAI APIì™€ í˜¸í™˜ë˜ëŠ” ì„œë²„ë¥¼ ìƒì„±í•œë‹¤.
# ë”°ë¼ì„œ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
client = OpenAI(
    base_url="http://localhost:8000/v1", # ğŸ’¡ ì ‘ì† ì£¼ì†Œë¥¼ ìš°ë¦¬ vLLM ì„œë²„ë¡œ ë³€ê²½
    api_key="NOT_USED"                   # ğŸ’¡ ë¡œì»¬ ì„œë²„ë¼ API í‚¤ëŠ” í•„ìš” ì—†ìŒ
)

# vLLM ì„œë²„ì— ì˜¬ë¼ê°€ ìˆëŠ” ëª¨ë¸ì˜ ID
MODEL_ID = "rucipheryn/Qwen2.5-14B-KB-Finance-LoRA-v2-Merged"


# --- 2. ë©”ì¸ ëŒ€í™” ë£¨í”„ ---
def main():
    print("\n=============================================")
    print("  KB ê¸ˆìœµ ì±—ë´‡ í„°ë¯¸ë„ (vLLM êµ¬ë™)")
    print("  (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”)")
    print("=============================================")

    # ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    messages = [
    {
        "role": "system",
        "content": (
            "You are a professional financial assistant for KB Financial Group. "
            "CRITICAL: Write ALL answers in Korean ONLY, using a friendly informal tone (banmal) appropriate for a colleague. "
            "Do NOT use English in the output unless the user explicitly asks; keep the entire response in Korean.\n\n"

            "## Style & Structure\n"
            "- Use Markdown with clear sections and bullets.\n"
            "- Always follow this layout:\n"
            "  1) ## ìš”ì•½ â€” one-line takeaway\n"
            "  2) ## í•µì‹¬ í¬ì¸íŠ¸ â€” 3â€“5 bullets\n"
            "  3) ## ìƒì„¸ ì„¤ëª… â€” concepts â†’ context â†’ steps/examples\n"
            "  4) ## í‘œ (í•„ìš” ì‹œ) â€” simple table\n"
            "  5) ## ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ (ì„ íƒ) â€” 1â€“3 clarifying items\n\n"

            "## Accuracy & Safety\n"
            "- Prioritize factual accuracy; if unknown or uncertain, say 'ëª¨ë¥´ê² ë‹¤' and state what info is needed.\n"
            "- When discussing Korean retail banking/loans, reflect the local context (e.g., Bank of Korea base rate as a policy rate, COFIX as a common floating index) when relevant, and include dates like YYYY-MM-DD for time-sensitive figures.\n"
            "- Avoid inventing numbers or sources; do not include sensitive personal data.\n\n"

            "## Formatting Rules (in Korean output)\n"
            "- Currency: ì›(â‚©) with thousand separators (e.g., 1,234,000ì›).\n"
            "- Rates: 2.5% ; changes as percentage points (e.g., +0.25%p).\n"
            "- Define financial acronyms on first use (ì˜ˆ: APR, APY, COFIX, ê¸°ì¤€ê¸ˆë¦¬).\n"
        )
    }
]

    while True:
        # 1. ì‚¬ìš©ìë¡œë¶€í„° ì§ˆë¬¸ ì…ë ¥ë°›ê¸°
        user_input = input("\nğŸ‘¤ ë‹¹ì‹ : ")
        if user_input.lower() in ["exit", "quit"]:
            print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        # 2. ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        messages.append({"role": "user", "content": user_input})

        print("\nğŸ¤– KB ì±—ë´‡ì´ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
        
        try:
            # 3. vLLM ì„œë²„ì— API ìš”ì²­
            response = client.chat.completions.create(
                model=MODEL_ID,
                messages=messages,
                max_tokens=1024,
                temperature=0.7,
            )
            
            # 4. ë‹µë³€ ì¶”ì¶œ ë° ì¶œë ¥
            assistant_response = response.choices[0].message.content
            print(f"\nğŸ¤– KB ì±—ë´‡: {assistant_response}")
            
            # 5. ëŒ€í™” ê¸°ë¡ì— ëª¨ë¸ ë‹µë³€ ì¶”ê°€ (ì—°ì†ì ì¸ ëŒ€í™”ë¥¼ ìœ„í•´)
            messages.append({"role": "assistant", "content": assistant_response})

        except Exception as e:
            print(f"\nâ—ï¸ ì„œë²„ì™€ í†µì‹  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    main()