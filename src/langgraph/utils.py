"""
LangGraph ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
============================
ì¤‘ë³µ ì½”ë“œë¥¼ ì œê±°í•˜ê³  ê³µí†µ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
"""

import json
import os
import logging
import sys
import threading
import time
import yaml
from typing import List, Dict, Any, Optional
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage

logger = logging.getLogger(__name__)

# ========== ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬ ==========

class SLMManager:
    """SLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹±ê¸€í†¤ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    _instance = None
    _slm_instance = None
    _lock = threading.Lock() if threading else None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def get_slm(self):
        """SLM ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (í•„ìš”ì‹œ ìƒì„±)"""
        if self._slm_instance is None:
            # ì§€ì—° importë¡œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€
            from ..slm.slm import SLM
            self._slm_instance = SLM()
            logger.debug("SLM instance created and cached")
        return self._slm_instance


class VectorStoreManager:
    """VectorStore ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹±ê¸€í†¤ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    _instance = None
    _vector_store_instance = None
    _lock = threading.Lock() if threading else None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def get_vector_store(self):
        """VectorStore ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (í•„ìš”ì‹œ ìƒì„±)"""
        if self._vector_store_instance is None:
            # ì§€ì—° importë¡œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€
            from ..rag.vector_store import VectorStore
            self._vector_store_instance = VectorStore()
            self._vector_store_instance.get_index_ready()  # í•œ ë²ˆë§Œ ì´ˆê¸°í™”
            logger.debug("VectorStore instance created and cached")
        return self._vector_store_instance


# ì „ì—­ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
_slm_manager = SLMManager()
_vector_store_manager = VectorStoreManager()


def get_shared_slm():
    """ê³µìœ  SLM ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    return _slm_manager.get_slm()


def get_shared_vector_store():
    """ê³µìœ  VectorStore ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    return _vector_store_manager.get_vector_store()


# ========== ìƒìˆ˜ ì •ì˜ ==========
DEFAULT_SEARCH_K = 3  # ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ ê°ì†Œ (ì†ë„ ê°œì„ )
DEFAULT_MAX_TURNS = 20  # ëŒ€í™” í„´ ìˆ˜ ê°ì†Œ (ì†ë„ ê°œì„ )
DEFAULT_MAX_MESSAGES = 50  # ë©”ì‹œì§€ ìˆ˜ ê°ì†Œ (ì†ë„ ê°œì„ )
DEFAULT_MESSAGE_HISTORY_LIMIT = 20  # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì œí•œ (ì†ë„ ê°œì„ )

# ========== ì„±ëŠ¥ ìµœì í™” ìƒìˆ˜ ==========
MAX_CONTEXT_LENGTH = 2000  # ì»¨í…ìŠ¤íŠ¸ ìµœëŒ€ ê¸¸ì´
MAX_QUERY_LENGTH = 500  # ì¿¼ë¦¬ ìµœëŒ€ ê¸¸ì´
CACHE_TTL_SECONDS = 300  # ìºì‹œ TTL (5ë¶„)
MAX_CACHE_SIZE = 100  # ìµœëŒ€ ìºì‹œ í¬ê¸°
BATCH_SIZE = 5  # ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°

# ========== ì—ëŸ¬ ë©”ì‹œì§€ (prompts.yamlì—ì„œ ë¡œë“œ) ==========

# ========== í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ í•¨ìˆ˜ë“¤ ==========

# í”„ë¡¬í”„íŠ¸ ìºì‹œ (ì „ì—­ ë³€ìˆ˜ë¡œ í•œ ë²ˆë§Œ ë¡œë“œ)
_prompts_cache: Optional[Dict[str, Any]] = None
_cache_lock = threading.Lock() if 'threading' in sys.modules else None

def load_prompts() -> Dict[str, Any]:
    """Load prompts from YAML file with caching"""
    global _prompts_cache
    
    if _prompts_cache is not None:
        return _prompts_cache
    
    current_dir = os.path.dirname(__file__)
    prompts_path = os.path.join(current_dir, "prompts.yaml")
    
    try:
        with open(prompts_path, 'r', encoding='utf-8') as f:
            _prompts_cache = yaml.safe_load(f)
            logger.debug("Prompts loaded and cached successfully")
            return _prompts_cache
    except FileNotFoundError:
        logger.warning(f"Prompts file not found: {prompts_path}")
        _prompts_cache = {}
        return _prompts_cache
    except Exception as e:
        logger.error(f"Error loading prompts: {e}")
        _prompts_cache = {}
        return _prompts_cache


def get_prompt(category: str, **kwargs) -> str:
    """
    Get formatted prompt from YAML template
    
    Args:
        category: Prompt category (supervisor, routing_prompts, etc.)
        **kwargs: Variables to format into the prompt template
        
    Returns:
        Formatted prompt string
    """
    prompts = load_prompts()
    
    # system_prompts ì„¹ì…˜ì—ì„œ ì°¾ê¸°
    if category in prompts.get("system_prompts", {}):
        prompt_template = prompts["system_prompts"][category]["system"]
    # routing_prompts ì„¹ì…˜ì—ì„œ ì°¾ê¸°
    elif category in prompts.get("routing_prompts", {}):
        prompt_template = prompts["routing_prompts"][category]
    else:
        logger.warning(f"Prompt category '{category}' not found")
        return f"í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {category}"
    
    try:
        return prompt_template.format(**kwargs)
    except KeyError as e:
        logger.error(f"Prompt formatting error: {e}")
        return f"í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ì˜¤ë¥˜: {e}"


def get_error_message(message_key: str, **kwargs) -> str:
    """
    Get error message with formatting
    
    Args:
        message_key: Key in error_messages section
        **kwargs: Variables to format into the message
        
    Returns:
        Formatted error message
    """
    prompts = load_prompts()
    
    if "error_messages" not in prompts:
        return "ê¸°ë³¸ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    error_messages = prompts["error_messages"]
    
    if message_key not in error_messages:
        return "í•´ë‹¹ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    message_template = error_messages[message_key]
    try:
        return message_template.format(**kwargs)
    except KeyError as e:
        logger.error(f"Error message formatting error: {e}")
        return f"ì—ëŸ¬ ë©”ì‹œì§€ ë³€ìˆ˜ ì˜¤ë¥˜: {e}"


# ========== ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (í˜¸í™˜ì„± ìœ ì§€) - ì œê±°ë¨ ==========
# SYSTEM_PROMPTS ë”•ì…”ë„ˆë¦¬ëŠ” prompts.yamlë¡œ ì´ê´€ë˜ì—ˆìŠµë‹ˆë‹¤.
# get_prompt() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•˜ì„¸ìš”.

def create_title_generation_prompt(query: str) -> str:
    """
    ì œëª© ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    Args:
        query (str): ì‚¬ìš©ì ì¿¼ë¦¬
        
    Returns:
        str: ì œëª© ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
    """
    return f"""ë‹¹ì‹ ì€ 'ì±—ë´‡ ì„¸ì…˜ ì œëª© ìƒì„±ê¸°'ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³  
        ì´ ì„¸ì…˜ì„ ëŒ€í‘œí•  ë§¤ìš° ê°„ê²°í•œ í•œ ì¤„ ì œëª©ì„ ìƒì„±í•˜ì„¸ìš”.

        ì‚¬ìš©ì ì§ˆë¬¸: {query}

        ì¶œë ¥: ì œëª© í…ìŠ¤íŠ¸ë§Œ í•œ ì¤„ë¡œ ì¶œë ¥
        - í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ (ë°˜ë“œì‹œ 15ì ì´í•˜)
        - ë¶ˆí•„ìš”í•œ ì„¤ëª… ì—†ì´ ì œëª©ë§Œ ë°˜í™˜
        - ì˜ˆì‹œ: 'í–‡ì‚´ë¡  ë¬¸ì˜', 'ëŒ€ì¶œ ë¬¸ì˜', 'ìƒí’ˆ ì•ˆë‚´'
        - ì¤‘ìš”: 15ìë¥¼ ì´ˆê³¼í•˜ë©´ ì•ˆë©ë‹ˆë‹¤!"""


def truncate_title(title: str, max_length: int = 15) -> str:
    """
    ì œëª©ì„ ì§€ì •ëœ ê¸¸ì´ë¡œ ìë¥´ê¸°
    
    Args:
        title (str): ì›ë³¸ ì œëª©
        max_length (int): ìµœëŒ€ ê¸¸ì´ (ê¸°ë³¸ê°’: 15)
        
    Returns:
        str: ì˜ë¦° ì œëª©
    """
    if len(title) > max_length:
        return title[:max_length].rstrip()
    return title


def generate_session_title(query: str, slm_instance) -> str:
    """
    ì„¸ì…˜ ì œëª© ìƒì„± (ì™„ì „í•œ ë¡œì§)
    
    Args:
        query (str): ì‚¬ìš©ì ì¿¼ë¦¬
        slm_instance: SLM ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        str: ìƒì„±ëœ ì„¸ì…˜ ì œëª©
    """
    try:
        # LLMìœ¼ë¡œ ì œëª© ìƒì„±
        title_prompt = create_title_generation_prompt(query)
        logger.info(f"Title generation prompt: {title_prompt}")
        
        raw_title = (slm_instance.invoke(title_prompt) or "").strip()
        logger.info(f"Raw title from LLM: '{raw_title}'")
        
        if raw_title:
            session_title = raw_title.splitlines()[0].strip()
            # 15ì ì œí•œ ê°•ì œ ì ìš©
            session_title = truncate_title(session_title, 15)
            logger.info(f"Final session title: '{session_title}'")
            return session_title
        else:
            # LLM ì‹¤íŒ¨ì‹œ í´ë°±
            fallback_title = truncate_title(query, 15)
            logger.info(f"LLM failed, using fallback title: '{fallback_title}'")
            return fallback_title
            
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒì‹œ í´ë°±
        fallback_title = truncate_title(query, 15)
        logger.error(f"Title generation error: {e}, using fallback: '{fallback_title}'")
        return fallback_title


def format_context(documents: List[Document]) -> str:
    """
    ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ… (ì„±ëŠ¥ ìµœì í™”)
    
    Args:
        documents: Document ë¦¬ìŠ¤íŠ¸
        
    Returns:
        str: í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    lines = []
    current_length = 0
    
    for i, doc in enumerate(documents, 1):
        if current_length >= MAX_CONTEXT_LENGTH:
            break
            
        src = doc.metadata.get("source", f"document_{i}") if doc.metadata else f"document_{i}"
        snippet = doc.page_content.strip()
        if not snippet:
            continue
        
        # ê° ë¬¸ì„œì˜ ë‚´ìš©ì„ 500ìë¡œ ì œí•œ
        if len(snippet) > 500:
            snippet = snippet[:500] + "..."
        
        line = f"[source: {src}]\n{snippet}"
        lines.append(line)
        current_length += len(line) + 5  # "\n---\n" ê¸¸ì´ ê³ ë ¤
    
    return "\n---\n".join(lines)


def extract_sources_from_docs(documents: List[Document]) -> List[Dict[str, Any]]:
    """
    ë¬¸ì„œë“¤ì—ì„œ ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ (í”„ë¡ íŠ¸ì—”ë“œ í‘œì‹œìš©)
    
    Args:
        documents: Document ë¦¬ìŠ¤íŠ¸
        
    Returns:
        List[Dict]: ì†ŒìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (í”„ë¡ íŠ¸ì—”ë“œ ì¹œí™”ì  êµ¬ì¡°)
    """
    sources = []
    for i, doc in enumerate(documents):
        metadata = doc.metadata or {}
        
        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í‘œì‹œí•˜ê¸° ì‰¬ìš´ êµ¬ì¡°ë¡œ ë³€í™˜
        source_info = {
            'id': i + 1,  # ì†ŒìŠ¤ ID
            'file_name': metadata.get('file_name', 'Unknown'),  # PDF íŒŒì¼ëª…
            'file_path': metadata.get('file_path', ''),  # íŒŒì¼ ê²½ë¡œ
            'page_number': metadata.get('page_number', 0),  # í˜ì´ì§€ ë²ˆí˜¸
            'main_category': metadata.get('main_category', ''),  # ë©”ì¸ ì¹´í…Œê³ ë¦¬
            'sub_category': metadata.get('sub_category', ''),  # ì„œë¸Œ ì¹´í…Œê³ ë¦¬
            'text': doc.page_content[:200] + '...' if len(doc.page_content) > 200 else doc.page_content,  # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            'full_text': doc.page_content,  # ì „ì²´ ë‚´ìš©
            'relevance_score': getattr(doc, 'score', 0.0) if hasattr(doc, 'score') else 0.0,  # ê´€ë ¨ë„ ì ìˆ˜
        }
        
        # ì›ë³¸ ë©”íƒ€ë°ì´í„°ë„ ë³´ì¡´ (í•„ìš”ì‹œ ì‚¬ìš©)
        source_info['metadata'] = metadata
        
        sources.append(source_info)
    
    logger.debug(f"ğŸ“„ [SOURCES] ì¶”ì¶œëœ ì†ŒìŠ¤ ì •ë³´: {len(sources)}ê°œ")
    
    return sources


def create_rag_response(slm_instance, query: str, documents: List[Document]) -> tuple[str, List[Dict[str, Any]]]:
    """
    RAG ê²€ìƒ‰ ê²°ê³¼ë¡œë¶€í„° ì‘ë‹µ ìƒì„±
    
    Args:
        slm_instance: SLM ì¸ìŠ¤í„´ìŠ¤
        query: ì‚¬ìš©ì ì¿¼ë¦¬
        documents: ê²€ìƒ‰ëœ ë¬¸ì„œë“¤
        
    Returns:
        tuple: (ì‘ë‹µ í…ìŠ¤íŠ¸, ì†ŒìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸)
    """
    if not documents:
        return get_error_message("no_documents"), []
    
    # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context_text = format_context(documents)
    
    # LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±
    system_prompt = get_prompt("rag_system", context_text=context_text)
    messages = [HumanMessage(content=system_prompt), HumanMessage(content=query)]
    response = slm_instance.invoke(messages)
    
    # ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ
    sources = extract_sources_from_docs(documents)
    
    return response, sources


def create_simple_response(slm_instance, query: str, prompt_type: str) -> str:
    """
    ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ìƒì„±
    
    Args:
        slm_instance: SLM ì¸ìŠ¤í„´ìŠ¤
        query: ì‚¬ìš©ì ì¿¼ë¦¬
        prompt_type: í”„ë¡¬í”„íŠ¸ íƒ€ì… (faq_system ë“±)
        
    Returns:
        str: ìƒì„±ëœ ì‘ë‹µ
    """
    try:
        # prompt_typeì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (YAML í‚¤ì™€ ë§¤ì¹˜)
        prompt = get_prompt(prompt_type, query=query)
        return slm_instance.invoke(prompt)
    except Exception:
        return get_error_message(f"{prompt_type.replace('_system', '_error')}")


def trim_message_history(messages: List[BaseMessage], max_messages: int = DEFAULT_MESSAGE_HISTORY_LIMIT) -> List[BaseMessage]:
    """
    ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ì œí•œí•˜ì—¬ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
    
    Args:
        messages: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        max_messages: ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜ (ê¸°ë³¸ê°’: 50)
        
    Returns:
        ì œí•œëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (ìµœì‹  ë©”ì‹œì§€ë“¤ë§Œ ìœ ì§€)
    """
    if len(messages) <= max_messages:
        return messages
        
    # ìµœì‹  ë©”ì‹œì§€ë“¤ë§Œ ìœ ì§€
    trimmed_messages = messages[-max_messages:]
    logger.info(f"Message history trimmed: {len(messages)} -> {len(trimmed_messages)}")
    return trimmed_messages


def create_guardrail_response(slm_instance, response: str) -> tuple[str, List[str]]:
    """
    ê°€ë“œë ˆì¼ ê²€ì‚¬ ë° ì‘ë‹µ ìƒì„±
    
    Args:
        slm_instance: SLM ì¸ìŠ¤í„´ìŠ¤
        response: ê²€ì‚¬í•  ì‘ë‹µ
        
    Returns:
        tuple: (ì¤€ìˆ˜ ì‘ë‹µ, ìœ„ë°˜ ì‚¬í•­ ë¦¬ìŠ¤íŠ¸)
    """
    try:
        # ê°€ë“œë ˆì¼ ë¹„í™œì„±í™” ì˜µì…˜ (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´)
        import os
        if os.getenv("DISABLE_GUARDRAIL", "false").lower() == "true":
            logger.info("ğŸ›¡ï¸ [GUARDRAIL] Disabled by environment variable")
            return response, []
        
        logger.info("ğŸ›¡ï¸ [GUARDRAIL] Loading config...")
        # YAML ì •ì±… ê¸°ë°˜ ê°€ë“œë ˆì¼ ê²€ì‚¬
        guardrail_config = load_guardrail_config()
        logger.info("ğŸ›¡ï¸ [GUARDRAIL] Config loaded")
        
        # ê¸°ë³¸ ì‘ë‹µ
        compliant_response = response
        violations = []
        
        # í’ˆì§ˆ ê²€ì‚¬ (ë¹ ë¥¸ ì²´í¬ ìš°ì„ )
        logger.info("ğŸ›¡ï¸ [GUARDRAIL] Checking completeness...")
        if guardrail_config.get("quality", {}).get("completeness_check", {}).get("enabled", False):
            violations.extend(check_completeness(response, guardrail_config))
        
        # ì •í™•ì„± ê²€ì‚¬ (ë” ë³µì¡í•œ ê²€ì‚¬)
        logger.info("ğŸ›¡ï¸ [GUARDRAIL] Checking accuracy...")
        if guardrail_config.get("quality", {}).get("accuracy_check", {}).get("enabled", False):
            violations.extend(check_accuracy(response, guardrail_config))
        
        # ìš©ì–´ ì •ê·œí™” (ìºì‹± ì ìš©)
        logger.info("ğŸ›¡ï¸ [GUARDRAIL] Normalizing terminology...")
        if guardrail_config.get("terminology", {}).get("normalization", {}).get("enabled", False):
            compliant_response = normalize_terminology(compliant_response, guardrail_config)
        
        # êµ¬ì¡° ê²€ì‚¬ (ì„ íƒì )
        logger.info("ğŸ›¡ï¸ [GUARDRAIL] Applying emphasis...")
        if guardrail_config.get("structure", {}).get("emphasis", {}).get("enabled", False):
            compliant_response = apply_emphasis(compliant_response, guardrail_config)
        
        # ìœ„ë°˜ì´ ìˆëŠ” ê²½ìš° ì•ˆì „í•œ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´
        if violations:
            logger.warning(f"ğŸ›¡ï¸ [GUARDRAIL] Found {len(violations)} violations")
            compliant_response = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. ê´€ë ¨ ë¶€ì„œì— ë¬¸ì˜í•´ì£¼ì„¸ìš”."
        
        logger.info("ğŸ›¡ï¸ [GUARDRAIL] Guardrail check completed")
        return compliant_response, violations
        
    except Exception as e:
        logger.error(f"ğŸ›¡ï¸ [GUARDRAIL] Error: {e}")
        return get_error_message("guardrail_error"), ["ê°€ë“œë ˆì¼ ê²€ì‚¬ ì˜¤ë¥˜"]


# ì „ì—­ ìºì‹œ ë³€ìˆ˜
_guardrail_config_cache = None
_glossary_terms_cache = None
_search_cache = {}  # ê²€ìƒ‰ ê²°ê³¼ ìºì‹±
_conversation_history_cache = {}  # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìºì‹±

def get_cached_search_result(query: str, product_name: str = "") -> Optional[List[Document]]:
    """ê²€ìƒ‰ ê²°ê³¼ ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê¸° (TTL ì²´í¬ í¬í•¨)"""
    cache_key = f"{query}:{product_name}"
    if cache_key in _search_cache:
        cache_entry = _search_cache[cache_key]
        # TTL ì²´í¬
        if time.time() - cache_entry.get("timestamp", 0) < CACHE_TTL_SECONDS:
            return cache_entry.get("documents")
        else:
            # ë§Œë£Œëœ ìºì‹œ ì œê±°
            del _search_cache[cache_key]
    return None

def set_cached_search_result(query: str, product_name: str, documents: List[Document]) -> None:
    """ê²€ìƒ‰ ê²°ê³¼ ìºì‹œì— ì €ì¥ (TTL í¬í•¨)"""
    cache_key = f"{query}:{product_name}"
    _search_cache[cache_key] = {
        "documents": documents,
        "timestamp": time.time()
    }
    # ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
    if len(_search_cache) > MAX_CACHE_SIZE:
        # LRU ë°©ì‹ìœ¼ë¡œ ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
        oldest_key = min(_search_cache.keys(), 
                        key=lambda k: _search_cache[k].get("timestamp", 0))
        del _search_cache[oldest_key]

def get_django_conversation_history(session_id: str, limit: int = 10) -> List[Dict[str, Any]]:
    """
    Djangoì—ì„œ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (ìºì‹± + ì„±ëŠ¥ ìµœì í™”)
    
    Args:
        session_id: ì„¸ì…˜ ID
        limit: ìµœëŒ€ ë¡œë“œí•  ëŒ€í™” ìˆ˜
        
    Returns:
        ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    global _conversation_history_cache
    
    # ìºì‹œì—ì„œ í™•ì¸
    cache_key = f"history_{session_id}_{limit}"
    if cache_key in _conversation_history_cache:
        logger.info(f"ğŸ“š [HISTORY] Using cached conversation history for session {session_id}")
        return _conversation_history_cache[cache_key]
    
    try:
        # Djangoì—ì„œ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ (ì‹¤ì œ êµ¬í˜„ì€ Django API í˜¸ì¶œ)
        logger.info(f"ğŸ“š [HISTORY] Loading conversation history from Django for session {session_id}")
        
        # TODO: ì‹¤ì œ Django API í˜¸ì¶œ êµ¬í˜„
        # ì˜ˆì‹œ: 
        # import requests
        # response = requests.get(f"/api/conversation-history/{session_id}?limit={limit}")
        # history = response.json()
        
        # ì„ì‹œë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ (ì‹¤ì œ êµ¬í˜„ ì‹œ Django API í˜¸ì¶œ)
        history = []
        
        # ìºì‹œì— ì €ì¥ (TTL: 5ë¶„)
        _conversation_history_cache[cache_key] = {
            "data": history,
            "timestamp": time.time()
        }
        
        # ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        if len(_conversation_history_cache) > 50:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = min(_conversation_history_cache.keys(), 
                           key=lambda k: _conversation_history_cache[k].get("timestamp", 0))
            del _conversation_history_cache[oldest_key]
        
        return history
        
    except Exception as e:
        logger.error(f"ğŸ“š [HISTORY] Failed to load conversation history: {e}")
        return []

def clear_conversation_history_cache(session_id: str = None) -> None:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ìºì‹œ í´ë¦¬ì–´"""
    global _conversation_history_cache
    
    if session_id:
        # íŠ¹ì • ì„¸ì…˜ ìºì‹œë§Œ í´ë¦¬ì–´
        keys_to_remove = [key for key in _conversation_history_cache.keys() if f"history_{session_id}_" in key]
        for key in keys_to_remove:
            del _conversation_history_cache[key]
        logger.info(f"ğŸ“š [HISTORY] Cleared cache for session {session_id}")
    else:
        # ì „ì²´ ìºì‹œ í´ë¦¬ì–´
        _conversation_history_cache.clear()
        logger.info("ğŸ“š [HISTORY] Cleared all conversation history cache")

def load_guardrail_config() -> Dict[str, Any]:
    """ê°€ë“œë ˆì¼ YAML ì„¤ì • ë¡œë“œ (ìºì‹± ì ìš©)"""
    global _guardrail_config_cache
    
    if _guardrail_config_cache is not None:
        return _guardrail_config_cache
    
    try:
        current_dir = os.path.dirname(__file__)
        config_path = os.path.join(current_dir, "guardrails", "policy_rules.yaml")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            _guardrail_config_cache = yaml.safe_load(f)
            return _guardrail_config_cache
    except Exception as e:
        logger.error(f"Failed to load guardrail config: {e}")
        return {}


def check_accuracy(response: str, config: Dict[str, Any]) -> List[str]:
    """ì •í™•ì„± ê²€ì‚¬"""
    violations = []
    accuracy_config = config.get("quality", {}).get("accuracy_check", {})
    
    if not accuracy_config.get("enabled", False):
        return violations
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ì‚¬
    triggers = accuracy_config.get("triggers", {})
    keywords = triggers.get("keywords", [])
    
    # ì»¨í…ìŠ¤íŠ¸ ê°ì§€ ì„¤ì •
    context_detection = accuracy_config.get("context_detection", {})
    product_indicators = context_detection.get("product_indicators", [])
    banking_terms = context_detection.get("banking_terms", [])
    
    for keyword in keywords:
        if keyword in response:
            # ìƒí’ˆ ì„¤ëª… ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
            has_product_context = any(indicator in response for indicator in product_indicators)
            has_banking_context = any(term in response for term in banking_terms)
            
            if has_product_context or has_banking_context:
                logger.info(f"ğŸ›¡ï¸ [GUARDRAIL] Trigger keyword '{keyword}' found but product/banking context detected - allowing")
                continue
                
            logger.warning(f"ğŸ›¡ï¸ [GUARDRAIL] Found trigger keyword: '{keyword}' in response")
            violations.append(f"ê²€ì¦ì´ í•„ìš”í•œ í‚¤ì›Œë“œ í¬í•¨: {keyword}")
    
    return violations


def check_completeness(response: str, config: Dict[str, Any]) -> List[str]:
    """ì™„ì „ì„± ê²€ì‚¬"""
    violations = []
    completeness_config = config.get("quality", {}).get("completeness_check", {})
    
    if not completeness_config.get("enabled", False):
        return violations
    
    # ê¸°ë³¸ì ì¸ ì™„ì „ì„± ê²€ì‚¬
    if len(response.strip()) < 50:
        violations.append("ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")
    
    return violations


def normalize_terminology(response: str, config: Dict[str, Any]) -> str:
    """ìš©ì–´ ì •ê·œí™” (ìºì‹± ì ìš©)"""
    global _glossary_terms_cache
    
    try:
        # ìºì‹œì—ì„œ ë¡œë“œ
        if _glossary_terms_cache is None:
            current_dir = os.path.dirname(__file__)
            glossary_path = os.path.join(current_dir, "guardrails", "glossary_terms.yaml")
            
            with open(glossary_path, 'r', encoding='utf-8') as f:
                _glossary_terms_cache = yaml.safe_load(f)
        
        # ìš©ì–´ ì¹˜í™˜
        terms = _glossary_terms_cache.get("terms", [])
        for term in terms:
            from_term = term.get("from", "")
            to_term = term.get("to", "")
            if from_term and to_term:
                response = response.replace(from_term, to_term)
        
        return response
    except Exception as e:
        logger.error(f"Terminology normalization failed: {e}")
        return response


def apply_emphasis(response: str, config: Dict[str, Any]) -> str:
    """ê°•ì¡° ì ìš©"""
    emphasis_config = config.get("structure", {}).get("emphasis", {})
    
    if not emphasis_config.get("enabled", False):
        return response
    
    # ê¸°ë³¸ì ì¸ ê°•ì¡° ì ìš© (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
    priority_keywords = emphasis_config.get("priority_keywords", {})
    
    for keyword, priority in priority_keywords.items():
        if keyword in response and priority >= 3:
            # ì¤‘ìš” í‚¤ì›Œë“œ ê°•ì¡° (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ì²˜ë¦¬ í•„ìš”)
            pass
    
    return response


def extract_product_name(slm_instance, query: str) -> str:
    """
    ìƒí’ˆëª… ì¶”ì¶œ (ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ì‚¬ìš©)
    
    Args:
        slm_instance: SLM ì¸ìŠ¤í„´ìŠ¤
        query: ì‚¬ìš©ì ì¿¼ë¦¬
        
    Returns:
        str: ì¶”ì¶œëœ ìƒí’ˆëª…
    """
    try:
        # ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ì‚¬ìš©
        prompt = get_prompt("product_extraction", query=query)
        extracted_product = slm_instance.invoke(prompt).strip()
        
        # ëŒ€ê´„í˜¸ ì œê±° ë° ì •ë¦¬
        if extracted_product.startswith('[') and extracted_product.endswith(']'):
            extracted_product = extracted_product[1:-1].strip()
        
        return extracted_product
        
    except Exception as e:
        logger.error(f"Product extraction failed: {e}")
        return "ì¼ë°˜"


def classify_product_subcategory(product_name: str) -> str:
    """
    ìƒí’ˆëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    
    Args:
        product_name: ì¶”ì¶œëœ ìƒí’ˆëª…
        
    Returns:
        str: ì„œë¸Œ ì¹´í…Œê³ ë¦¬
    """
    from .models import LoanSubType, DepositSubType, CardSubType, SavingsSubType
    
    product_lower = product_name.lower()
    
    # ëŒ€ì¶œ ìƒí’ˆ ë¶„ë¥˜
    if any(keyword in product_lower for keyword in ["í–‡ì‚´ë¡ ", "ë‹¥í„°ë¡ ", "ë¡œì´ì–´ë¡ "]):
        return LoanSubType.PERSONAL_CREDIT.value
    elif any(keyword in product_lower for keyword in ["ë‚´ì§‘ë§ˆë ¨", "ì…ì£¼ì", "ëŒ€í™˜"]):
        return LoanSubType.PERSONAL_HOUSING_FUND.value
    elif any(keyword in product_lower for keyword in ["ë²„íŒ€ëª©", "ì „ì„¸"]):
        return LoanSubType.PERSONAL_SECURED_JEONSE.value
    elif any(keyword in product_lower for keyword in ["ë§¤ì§ì¹´", "ìë™ì°¨"]):
        return LoanSubType.PERSONAL_AUTO.value
    elif any(keyword in product_lower for keyword in ["êµ°ì¸", "íì—…", "ê¸°ì—…"]):
        return LoanSubType.BUSINESS_LOAN.value
    
    # ì˜ˆê¸ˆ/ì ê¸ˆ ìƒí’ˆ ë¶„ë¥˜
    elif any(keyword in product_lower for keyword in ["ì˜ˆê¸ˆ", "ì •ê¸°ì˜ˆê¸ˆ"]):
        return DepositSubType.TIME_DEPOSIT.value
    elif any(keyword in product_lower for keyword in ["ì ê¸ˆ", "ì •ê¸°ì ê¸ˆ"]):
        return SavingsSubType.REGULAR_SAVINGS.value
    elif any(keyword in product_lower for keyword in ["ììœ ì ê¸ˆ"]):
        return SavingsSubType.FREE_SAVINGS.value
    elif any(keyword in product_lower for keyword in ["ì£¼íƒì²­ì•½"]):
        return SavingsSubType.HOUSING_SAVINGS.value
    
    # ì¹´ë“œ ìƒí’ˆ ë¶„ë¥˜
    elif any(keyword in product_lower for keyword in ["ì¹´ë“œ", "ì‹ ìš©ì¹´ë“œ"]):
        return CardSubType.CREDIT_CARD.value
    elif any(keyword in product_lower for keyword in ["ì²´í¬ì¹´ë“œ"]):
        return CardSubType.DEBIT_CARD.value
    
    # ê¸°ë³¸ê°’
    else:
        return "ì¼ë°˜"


def create_supervisor_prompt(query: str) -> str:
    """
    ìŠˆí¼ë°”ì´ì € í”„ë¡¬í”„íŠ¸ ìƒì„± (ìƒˆë¡œìš´ 3ê°€ì§€ ë…¸ë“œ ì›Œí¬í”Œë¡œìš°ìš©)
    
    Args:
        query: ì‚¬ìš©ì ì¿¼ë¦¬
        
    Returns:
        str: ìŠˆí¼ë°”ì´ì € í”„ë¡¬í”„íŠ¸
    """
    try:
        return get_prompt("supervisor", query=query)
    except KeyError as e:
        logger.error(f"Prompt formatting error: {e}")
        # í´ë°± í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        return f"""ë‹¹ì‹ ì€ KBê¸ˆìœµê·¸ë£¹ì˜ ì¤‘ì•™ ê´€ë¦¬ìì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë…¸ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.
        
        ì‚¬ìš©ì ì§ˆë¬¸: {query}
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ë…¸ë“œ:
        - answer: ìµœì¢… ë‹µë³€ ìƒì„±
        - rag_search: ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸
        - product_extraction: ìƒí’ˆëª… ì¶”ì¶œì´ í•„ìš”í•œ ì§ˆë¬¸
        
        ì ì ˆí•œ ë…¸ë“œë¥¼ ì„ íƒí•˜ê³  reasoningì„ ì œê³µí•˜ì„¸ìš”."""

def create_error_response(error_type: str, **kwargs) -> Dict[str, Any]:
    """
    ì—ëŸ¬ ì‘ë‹µ ìƒì„±
    
    Args:
        error_type: ì—ëŸ¬ íƒ€ì…
        **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
        
    Returns:
        Dict: ì—ëŸ¬ ì‘ë‹µ ë”•ì…”ë„ˆë¦¬
    """
    return {
        "response": get_error_message(error_type),
        "sources": kwargs.get("sources", []),
        "ready_to_answer": True
    }


# ========== ì„±ëŠ¥ ìµœì í™” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ==========

def optimize_query_length(query: str, max_length: int = MAX_QUERY_LENGTH) -> str:
    """ì¿¼ë¦¬ ê¸¸ì´ ìµœì í™”"""
    if len(query) > max_length:
        return query[:max_length].rsplit(' ', 1)[0] + "..."
    return query


def batch_process_items(items: List[Any], batch_size: int = BATCH_SIZE) -> List[List[Any]]:
    """ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ"""
    return [items[i:i + batch_size] for i in range(0, len(items), batch_size)]


def cleanup_expired_cache():
    """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
    global _search_cache, _conversation_history_cache
    current_time = time.time()
    
    # ê²€ìƒ‰ ìºì‹œ ì •ë¦¬
    expired_keys = []
    for key, value in _search_cache.items():
        if current_time - value.get("timestamp", 0) > CACHE_TTL_SECONDS:
            expired_keys.append(key)
    
    for key in expired_keys:
        del _search_cache[key]
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìºì‹œ ì •ë¦¬
    expired_history_keys = []
    for key, value in _conversation_history_cache.items():
        if current_time - value.get("timestamp", 0) > CACHE_TTL_SECONDS:
            expired_history_keys.append(key)
    
    for key in expired_history_keys:
        del _conversation_history_cache[key]
    
    if expired_keys or expired_history_keys:
        logger.info(f"ğŸ§¹ [CACHE] Cleaned up {len(expired_keys)} search cache and {len(expired_history_keys)} history cache entries")


def get_memory_usage() -> Dict[str, Any]:
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§"""
    import psutil
    import os
    
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    
    return {
        "rss_mb": memory_info.rss / 1024 / 1024,  # ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        "vms_mb": memory_info.vms / 1024 / 1024,  # ê°€ìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        "cache_size": len(_search_cache),
        "history_cache_size": len(_conversation_history_cache)
    }
