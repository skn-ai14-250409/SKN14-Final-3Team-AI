"""
LangGraph Nodes
==============
RAG ì›Œí¬í”Œë¡œìš°ì˜ ë…¸ë“œ í•¨ìˆ˜ë“¤
"""

import logging
import time
import re
from typing import Dict, List, Any

from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.documents import Document

from .models import RAGState
from .session_manager import session_manager
from .utils import (
    generate_session_title, 
    create_rag_response, 
    create_simple_response, 
    create_guardrail_response,
    extract_product_name,
    classify_product_subcategory,
    create_error_response,
    format_context,
    create_supervisor_prompt,
    DEFAULT_SEARCH_K,
    ERROR_MESSAGES
)
from ..slm.slm import SLM
from ..rag.vector_store import VectorStore

logger = logging.getLogger(__name__)

# ========== Utility Functions ==========

def clean_markdown_formatting(text: str) -> str:
    """ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì œê±°í•˜ê³  ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not text:
        return text
    
    # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì œê±°
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)  # **bold** -> bold
    text = re.sub(r'\*(.*?)\*', r'\1', text)      # *italic* -> italic
    text = re.sub(r'#+\s*', '', text)             # # headers -> headers
    text = re.sub(r'`(.*?)`', r'\1', text)        # `code` -> code
    text = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', text)  # [text](url) -> text
    text = re.sub(r'^\s*[-*+]\s*', '', text, flags=re.MULTILINE)  # bullet points
    text = re.sub(r'^\s*\d+\.\s*', '', text, flags=re.MULTILINE)  # numbered lists
    
    # ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
    text = re.sub(r'\n\s*\n', '\n\n', text)  # ì—¬ëŸ¬ ì¤„ë°”ê¿ˆì„ ë‘ ê°œë¡œ ì œí•œ
    text = text.strip()
    
    return text

# ========== Node Functions ==========

def session_init_node(state: RAGState) -> RAGState:
    """ì„¸ì…˜ ì´ˆê¸°í™”"""
    logger.info("[NODE] session_init_node ì‹¤í–‰ ì‹œì‘")
    try:
        session_id = state.get("session_context", {}).session_id if state.get("session_context") else None
        
        if not session_id:
            session_context = session_manager.create_session()
            logger.info(f"Created new session: {session_context.session_id}")
        else:
            session_context = session_manager.get_session(session_id)
            if not session_context:
                session_context = session_manager.create_session(session_id)
                logger.info(f"Recreated expired session: {session_id}")
        
        turn_id = f"turn_{int(time.time())}_{hash(str(time.time())) % 10000}"
        
        return {
            **state,
            "session_context": session_context,
            "turn_id": turn_id,
            "conversation_history": session_manager.get_conversation_history(session_context.session_id, limit=5),
            # ê° í„´ë§ˆë‹¤ ì´ˆê¸°í™”í•´ì•¼ í•  í•„ë“œë“¤
            "product_name": "",
            "product_extraction_result": None,
            "category": "",
            "initial_intent": "",
            "current_topic": "",
            "active_product": "",
            "session_title": "",  # session_title ì´ˆê¸°í™”
            "response": "",  # response ì´ˆê¸°í™”
            "sources": [],  # sources ì´ˆê¸°í™”
            "retrieved_docs": [],  # retrieved_docs ì´ˆê¸°í™”
            "context_text": "",  # context_text ì´ˆê¸°í™”
            "ready_to_answer": False,  # ready_to_answer ì´ˆê¸°í™”
            "guardrail_decision": "",  # guardrail_decision ì´ˆê¸°í™”
            "violations": [],  # violations ì´ˆê¸°í™”
            "compliant_response": ""  # compliant_response ì´ˆê¸°í™”
        }
        
    except Exception as e:
        logger.error(f"Session init failed: {e}")
        session_context = session_manager.create_session()
        return {
            **state,
            "session_context": session_context,
            "turn_id": f"turn_{int(time.time())}",
            "conversation_history": []
        }

def supervisor_node(state: RAGState, llm=None, slm: SLM = None) -> RAGState:
    """ì¤‘ì•™ ê´€ë¦¬ì - íˆ´ ì„ íƒ"""
    logger.info("[NODE] supervisor_node ì‹¤í–‰ ì‹œì‘")
    query = state.get("query", "")
    session_context = state.get("session_context")
    
    # SLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
    if slm is None:
        slm = SLM()
    
    # ì²« ëŒ€í™”ì¸ì§€ í™•ì¸ (conversation_historyê°€ ë¹„ì–´ìˆì„ ë•Œë§Œ)
    conversation_history = state.get("conversation_history", [])
    session_title = session_context.session_title if session_context else ""
    is_first_turn = not conversation_history or len(conversation_history) == 0
    
    logger.info(f"[SUPERVISOR] Query: '{query}' | First turn: {is_first_turn}")

    # ì²« ë²ˆì§¸ í„´ì¼ ë•Œ: session_summary ì œì™¸í•œ ë„êµ¬ë“¤ ì‚¬ìš© (ì´ë¯¸ SESSION_SUMMARY ë…¸ë“œì—ì„œ ì²˜ë¦¬ë¨)
    if is_first_turn:
        logger.info("[SUPERVISOR] First turn: Using tools (excluding session_summary)")
        from .tools import general_faq, rag_search, product_extraction, product_search, answer
        tool_functions = [general_faq, rag_search, product_extraction, product_search, answer]
    else:
        # ë‘ ë²ˆì§¸ í„´ ì´í›„: session_summary, intent_classification ì œì™¸í•œ ë„êµ¬ë“¤ë§Œ ì‚¬ìš©
        logger.info("[SUPERVISOR] Multi-turn: Using limited tools")
        from .tools import general_faq, rag_search, product_extraction, product_search, answer
        tool_functions = [general_faq, rag_search, product_extraction, product_search, answer]
    
    logger.info(f"Available tools: {[tool.name for tool in tool_functions]}")

    # ì´ë¯¸ ë¶„ë¥˜ëœ ì˜ë„ ì‚¬ìš© (intent_classification_nodeì—ì„œ ì„¤ì •ë¨)
    intent_category = state.get("intent_category", "general_banking_FAQs")
    
    # ì‘ë‹µì´ ì´ë¯¸ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
    current_response = state.get("response", "")
    has_response = bool(current_response.strip())
    
    # ìƒí’ˆëª…ì´ ì¶”ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
    extracted_product = state.get("product_name", "")
    has_product_name = bool(extracted_product.strip()) and extracted_product != "ì¼ë°˜"
    
    # ìŠˆí¼ë°”ì´ì € í”„ë¡¬í”„íŠ¸ ìƒì„±
    supervisor_prompt = create_supervisor_prompt(
        query=query,
        is_first_turn=is_first_turn,
        intent_category=intent_category,
        has_response=has_response,
        extracted_product=extracted_product,
        has_product_name=has_product_name
    )

    try:
        # LLMìœ¼ë¡œ íˆ´ ì„ íƒ
        result = slm.llm.bind_tools(tool_functions, tool_choice="required").invoke(supervisor_prompt)
        
        # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ stateì— ì €ì¥
        if hasattr(result, 'tool_calls') and result.tool_calls:
            tool_name = result.tool_calls[0]['name']
            tool_args = result.tool_calls[0]['args']
            
            logger.info(f"[SUPERVISOR] Selected tool: {tool_name} with args: {tool_args}")
            
            # ë„êµ¬ ì‹¤í–‰
            if tool_name == "general_faq":
                response = create_simple_response(slm, query, "faq_system")
                response = clean_markdown_formatting(response)
                return {
                    **state,
                    "messages": [result],
                    "response": response,
                    "ready_to_answer": True,
                    "n_tool_calling": state.get("n_tool_calling", 0) + 1,
                    "intent_category": intent_category,
                }
            elif tool_name == "rag_search":
                # RAG ê²€ìƒ‰ ì‹¤í–‰
                from ..rag.vector_store import VectorStore
                vector_store = VectorStore()
                vector_store.get_index_ready()
                retrieved_docs = vector_store.similarity_search(query, k=3)
                response, sources = create_rag_response(slm, query, retrieved_docs)
                response = clean_markdown_formatting(response)
                return {
                    **state,
                    "messages": [result],
                    "response": response,
                    "sources": sources,
                    "retrieved_docs": retrieved_docs,
                    "context_text": format_context(retrieved_docs) if retrieved_docs else "",
                    "ready_to_answer": True,
                    "n_tool_calling": state.get("n_tool_calling", 0) + 1,
                    "intent_category": intent_category,
                }
            elif tool_name == "product_extraction":
                # ìƒí’ˆëª… ì¶”ì¶œ ì‹¤í–‰
                extracted_product = extract_product_name(slm, query)
                sub_category = classify_product_subcategory(extracted_product)
                return {
                    **state,
                    "messages": [result],
                    "product_name": extracted_product,
                    "product_extraction_result": {
                        "product_name": extracted_product,
                        "sub_category": sub_category,
                        "confidence": 0.9,
                        "reasoning": f"ìƒí’ˆëª… '{extracted_product}'ì„ ì¶”ì¶œí•˜ê³  '{sub_category}'ë¡œ ë¶„ë¥˜"
                    },
                    "ready_to_answer": False,  # product_searchë¡œ ì´ì–´ì ¸ì•¼ í•¨
                    "n_tool_calling": state.get("n_tool_calling", 0) + 1,
                    "intent_category": intent_category,
                }
            elif tool_name == "product_search":
                # ìƒí’ˆ ê²€ìƒ‰ ì‹¤í–‰
                from ..rag.vector_store import VectorStore
                vector_store = VectorStore()
                vector_store.get_index_ready()
                product_name = state.get("product_name", "")
                
                if not product_name or product_name == "ì¼ë°˜":
                    retrieved_docs = vector_store.similarity_search(query, k=3)
                else:
                    # ìƒí’ˆëª…ìœ¼ë¡œ í•„í„°ë§ ì‹œë„
                    filter_attempts = [
                        {"product_name": product_name},
                        {"keywords": {"$in": [product_name]}},
                        {"file_name": {"$regex": product_name, "$options": "i"}},
                        {"product_type": product_name}
                    ]
                    
                    retrieved_docs = []
                    for filter_dict in filter_attempts:
                        try:
                            retrieved_docs = vector_store.similarity_search(query, k=3, filter_dict=filter_dict)
                            if retrieved_docs:
                                break
                        except Exception:
                            continue
                    
                    if not retrieved_docs:
                        retrieved_docs = vector_store.similarity_search(query, k=3)
                
                response, sources = create_rag_response(slm, query, retrieved_docs)
                response = clean_markdown_formatting(response)
                return {
                    **state,
                    "messages": [result],
                    "response": response,
                    "sources": sources,
                    "retrieved_docs": retrieved_docs,
                    "context_text": format_context(retrieved_docs) if retrieved_docs else "",
                    "ready_to_answer": True,
                    "n_tool_calling": state.get("n_tool_calling", 0) + 1,
                    "intent_category": intent_category,
                }
            elif tool_name == "answer":
                # ì§ì ‘ ë‹µë³€
                return {
                    **state,
                    "messages": [result],
                    "ready_to_answer": True,
                    "n_tool_calling": state.get("n_tool_calling", 0) + 1,
                    "intent_category": intent_category,
                }
        
        return {
            **state,
            "messages": [result],
            "n_tool_calling": state.get("n_tool_calling", 0) + 1,
            "intent_category": intent_category,
        }
        
    except Exception as e:
        logger.error(f"Supervisor failed: {e}")
        return {
            **state,
            "messages": [AIMessage(content="ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")],
            "ready_to_answer": True
        }

def supervisor_router(state: RAGState) -> str:
    """ìŠˆí¼ë°”ì´ì € ë¼ìš°í„°"""
    logger.info("[ROUTER] supervisor_router ì‹¤í–‰ ì‹œì‘")
    logger.info(f"[ROUTER] State keys: {list(state.keys())}")
    logger.info(f"[ROUTER] ready_to_answer: {state.get('ready_to_answer')}")
    
    # messagesì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ í™•ì¸
    messages = state.get("messages", [])
    if messages:
        last_message = messages[-1]
        logger.info(f"[ROUTER] Last message type: {type(last_message)}")
        logger.info(f"[ROUTER] Last message content: {getattr(last_message, 'content', 'No content')}")
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            logger.info(f"[ROUTER] Tool calls: {[call['name'] for call in last_message.tool_calls]}")
    
    if state.get("ready_to_answer"):
        logger.info("[ROUTER] ready_to_answer=True - ANSWERë¡œ ë¼ìš°íŒ…")
        return "answer"
    
    # ì²« ë²ˆì§¸ í„´ì¸ì§€ í™•ì¸
    conversation_history = state.get("conversation_history", [])
    is_first_turn = not conversation_history or len(conversation_history) == 0
    
    logger.info(f"[ROUTER] conversation_history: {conversation_history}")
    logger.info(f"[ROUTER] is_first_turn: {is_first_turn}")
    
    # messagesì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ì˜ ë„êµ¬ í˜¸ì¶œ í™•ì¸
    if messages:
        last_message = messages[-1]
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            tool_name = last_message.tool_calls[0]['name']
            logger.info(f"[ROUTER] Selected tool: {tool_name}")
            return tool_name
    
    # ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ RAG_SEARCHë¡œ
    logger.info("[ROUTER] No tool calls found - defaulting to RAG_SEARCH")
    return "rag_search"

def intent_classification_node(state: RAGState, slm: SLM = None) -> RAGState:
    """ì˜ë„ ë¶„ë¥˜ ë…¸ë“œ"""
    logger.info("ğŸ¯ [NODE] intent_classification_node ì‹¤í–‰ ì‹œì‘")
    query = state.get("query", "")
    
    # SLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
    if slm is None:
        slm = SLM()
    
    try:
        # ì˜ë„ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
        classification_prompt = f"""
            ë‹¤ìŒ ì§ˆë¬¸ì„ ì •í™•íˆ ë¶„ë¥˜í•´ì£¼ì„¸ìš”: {query}

            ë¶„ë¥˜ ê¸°ì¤€:
            1. general_banking_FAQs: ì¼ë°˜ì ì¸ ì€í–‰ ê°œë…ì´ë‚˜ ê¸ˆìœµ ìƒì‹ ì§ˆë¬¸
            - "ì˜ˆê¸ˆì´ ë­ì˜ˆìš”?", "ì ê¸ˆì´ ë­ì˜ˆìš”?", "ëŒ€ì¶œì´ ë­ì˜ˆìš”?", "ì¹´ë“œê°€ ë­ì˜ˆìš”?" ë“±
            - ì€í–‰ ì—…ë¬´ì˜ ê¸°ë³¸ ê°œë…ì— ëŒ€í•œ ì§ˆë¬¸
            - íŠ¹ì • ìƒí’ˆëª…ì´ë‚˜ ë¸Œëœë“œëª…ì´ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì¼ë°˜ì ì¸ ì§ˆë¬¸

            2. industry_policies_and_regulations: ì€í–‰ì—… ê·œì œ ë° ì •ì±… ê´€ë ¨
            - KYC, AML, ë°”ì ¤3, ê¸ˆìœµê°ë…ì› ê·œì • ë“±
            - ì€í–‰ì—…ê³„ ì „ë°˜ì˜ ê·œì œë‚˜ ì •ì±…ì— ëŒ€í•œ ì§ˆë¬¸

            3. company_rules: KBê¸ˆìœµê·¸ë£¹ ë‚´ë¶€ ê·œì¹™ ë° ì •ì±…
            - ì§ì› ë³µë¦¬í›„ìƒ, íœ´ê°€ì •ì±…, ë³µì¥ê·œì •, ì§ì› êµìœ¡, ì¸ì‚¬ì •ì±… ë“±
            - KBê¸ˆìœµê·¸ë£¹ ë‚´ë¶€ ì •ì±…ì´ë‚˜ ì§ì› ê´€ë ¨ ì§ˆë¬¸
            - "ì§ì›", "íœ´ê°€", "ë³µë¦¬í›„ìƒ", "ì¸ì‚¬", "êµìœ¡" ë“±ì´ í¬í•¨ëœ ì§ˆë¬¸

            4. company_products: KBê¸ˆìœµê·¸ë£¹ì˜ êµ¬ì²´ì ì¸ ìƒí’ˆëª…ì´ë‚˜ ë¸Œëœë“œëª…ì´ ì–¸ê¸‰ëœ ê²½ìš°
            - í–‡ì‚´ë¡ , ë‹¥í„°ë¡ , ë¡œì´ì–´ë¡ , ë‚´ì§‘ë§ˆë ¨ë””ë”¤ëŒëŒ€ì¶œ, ì…ì£¼ì ì• ëŒ€í™˜ëŒ€ì¶œ, ë²„íŒ€ëª© ì „ì„¸ìê¸ˆëŒ€ì¶œ, ë§¤ì§ì¹´ëŒ€ì¶œ, êµ°ì¸ ì—°ê¸ˆ í˜‘ì•½ ëŒ€ì¶œ, íì—…ì§€ì› ëŒ€í™˜ëŒ€ì¶œ ë“±
            - "KBì¹´ë“œ", "KBì˜ˆê¸ˆ", "KBì ê¸ˆ", "KBë³´í—˜", "KBí€ë“œ" ë“± KB ë¸Œëœë“œê°€ ëª…ì‹œëœ ê²½ìš°
            - "KB í–‡ì‚´ë¡ ", "í–‡ì‚´ë¡ ", "KBì¹´ë“œ" ë“±ì´ ì–¸ê¸‰ë˜ë©´ ë¬´ì¡°ê±´ company_products

            ì¤‘ìš”í•œ êµ¬ë¶„:
            - "ì˜ˆê¸ˆì´ ë­ì˜ˆìš”?" â†’ general_banking_FAQs (ì¼ë°˜ì ì¸ ê°œë… ì§ˆë¬¸)
            - "KBì˜ˆê¸ˆ ìƒí’ˆì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”" â†’ company_products (êµ¬ì²´ì ì¸ KB ìƒí’ˆ)
            - "ëŒ€ì¶œì´ ë­ì˜ˆìš”?" â†’ general_banking_FAQs (ì¼ë°˜ì ì¸ ê°œë… ì§ˆë¬¸)
            - "í–‡ì‚´ë¡  ëŒ€ì¶œì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”" â†’ company_products (êµ¬ì²´ì ì¸ ìƒí’ˆëª…)
            - "ì§ì› íœ´ê°€ ì •ì±…ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?" â†’ company_rules (ì§ì› ê´€ë ¨ ì •ì±…)
            - "ë³µë¦¬í›„ìƒ ì œë„ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?" â†’ company_rules (ì§ì› ê´€ë ¨ ì •ì±…)

            ì˜ˆì‹œ:
            - "ì˜ˆê¸ˆì´ ë­ì˜ˆìš”?" â†’ general_banking_FAQs
            - "ì ê¸ˆì´ ë­ì˜ˆìš”?" â†’ general_banking_FAQs
            - "ëŒ€ì¶œì´ ë­ì˜ˆìš”?" â†’ general_banking_FAQs
            - "í–‡ì‚´ë¡  ëŒ€ì¶œì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”" â†’ company_products
            - "KB í–‡ì‚´ë¡  ëŒ€ì¶œ ì¡°ê±´ê³¼ ê¸ˆë¦¬ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”" â†’ company_products
            - "KBì¹´ë“œ í˜œíƒì´ ë­ì˜ˆìš”?" â†’ company_products
            - "ì˜¤í”¼ìŠ¤í…”ì„ ë‹´ë³´ë¡œ ëŒ€ì¶œ ì‹ ì²­ì„ ì›í•˜ëŠ” ê³ ê°ì—ê²Œ ê´€ë ¨ ìƒí’ˆ ì¶”ì²œí•´ì£¼ê³ , ì •í™•í•œ ì‹ ì²­ ìê²© ì•Œë ¤ì¤˜" â†’ company_products
            - "KYC ê·œì •ì´ ë­ì˜ˆìš”?" â†’ industry_policies_and_regulations
            - "ì§ì› íœ´ê°€ ì •ì±…ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?" â†’ company_rules
            - "ë°”ì ¤3 ê·œì •ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”" â†’ industry_policies_and_regulations

            ì§ˆë¬¸: {query}

            ë¶„ë¥˜ ê²°ê³¼ë§Œ ì¶œë ¥í•˜ì„¸ìš” (general_banking_FAQs, industry_policies_and_regulations, company_rules, company_products ì¤‘ í•˜ë‚˜):
            """
        
        intent_category = slm.invoke(classification_prompt).strip()
        
        # ê²°ê³¼ ì •ë¦¬
        intent_category = intent_category.lower().strip()
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê°•í™” ë¶„ë¥˜
        query_lower = query.lower()
        logger.info(f"Original LLM classification: {intent_category}")
        logger.info(f"Query for keyword check: {query_lower}")
        
        if any(keyword in query_lower for keyword in ["ì§ì›", "íœ´ê°€", "ë³µë¦¬í›„ìƒ", "ì¸ì‚¬", "êµìœ¡", "ì •ì±…"]):
            intent_category = "company_rules"
            logger.info("Keyword-based classification: company_rules")
        elif any(keyword in query_lower for keyword in ["í–‡ì‚´ë¡ ", "ë‹¥í„°ë¡ ", "ë¡œì´ì–´ë¡ "]):
            intent_category = "company_products"
            logger.info("Keyword-based classification: company_products")
        elif any(keyword in query_lower for keyword in ["kyc", "aml", "ë°”ì ¤", "ê¸ˆìœµê°ë…ì›", "ê·œì •"]):
            intent_category = "industry_policies_and_regulations"
            logger.info("Keyword-based classification: industry_policies_and_regulations")
        elif "company_products" in intent_category:
            intent_category = "company_products"
        elif "industry_policies_and_regulations" in intent_category:
            intent_category = "industry_policies_and_regulations"
        elif "company_rules" in intent_category:
            intent_category = "company_rules"
        else:
            intent_category = "general_banking_FAQs"
        
        logger.info(f"Intent classified as: {intent_category}")
        
        return {
            **state,
            "intent_category": intent_category
        }
        
    except Exception as e:
        logger.error(f"Intent classification failed: {e}")
        return {
            **state,
            "intent_category": "general_banking_FAQs"  # ê¸°ë³¸ê°’
        }

def general_faq_node(state: RAGState, slm: SLM = None) -> RAGState:
    """ì¼ë°˜ ì€í–‰ FAQ ì²˜ë¦¬ ë…¸ë“œ (SLM ì§ì ‘ ë‹µë³€)"""
    logger.info("â“ [NODE] general_faq_node ì‹¤í–‰ ì‹œì‘")
    query = state.get("query", "")
    
    # SLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
    if slm is None:
        slm = SLM()
    
    try:
        response = create_simple_response(slm, query, "faq_system")
        return {
            **state,
            "response": response,
            "ready_to_answer": True
        }
        
    except Exception as e:
        logger.error(f"General FAQ failed: {e}")
        return {
            **state,
            **create_error_response("faq_error")
        }

def product_extraction_node(state: RAGState, slm: SLM = None) -> RAGState:
    """ìƒí’ˆëª… ì¶”ì¶œ ë…¸ë“œ"""
    logger.info("ğŸ·ï¸ [NODE] product_extraction_node ì‹¤í–‰ ì‹œì‘")
    query = state.get("query", "")
    
    # SLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
    if slm is None:
        slm = SLM()
    
    try:
        extracted_product = extract_product_name(slm, query)
        sub_category = classify_product_subcategory(extracted_product)
        logger.info(f"Extracted product: '{extracted_product}', Sub category: '{sub_category}'")
        
        return {
            **state,
            "product_name": extracted_product,
            "product_extraction_result": {
                "product_name": extracted_product,
                "sub_category": sub_category,
                "confidence": 0.9,
                "reasoning": f"ìƒí’ˆëª… '{extracted_product}'ì„ ì¶”ì¶œí•˜ê³  '{sub_category}'ë¡œ ë¶„ë¥˜"
            },
            "ready_to_answer": False  # ì•„ì§ ë‹µë³€ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ
        }
        
    except Exception as e:
        logger.error(f"Product extraction failed: {e}")
        return {
            **state,
            "product_name": "ì¼ë°˜",
            "ready_to_answer": False
        }

def product_search_node(state: RAGState, slm: SLM = None) -> RAGState:
    """ìƒí’ˆ ê²€ìƒ‰ ë…¸ë“œ"""
    logger.info("ğŸ” [NODE] product_search_node ì‹¤í–‰ ì‹œì‘")
    query = state.get("query", "")
    product_name = state.get("product_name", "")
    
    # SLMê³¼ VectorStore ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    if slm is None:
        slm = SLM()
    vector_store = VectorStore()
    
    try:
        vector_store.get_index_ready()
        
        if not product_name or product_name == "ì¼ë°˜":
            # ì¼ë°˜ ê²€ìƒ‰
            retrieved_docs = vector_store.similarity_search(query, k=DEFAULT_SEARCH_K)
            logger.info(f"General search found {len(retrieved_docs)} documents")
        else:
            # ìƒí’ˆëª…ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° í•„í„°ë§ (ì—¬ëŸ¬ í•„ë“œ ì‹œë„)
            filter_attempts = [
                {"product_name": product_name},
                {"keywords": {"$in": [product_name]}},
                {"file_name": {"$regex": product_name, "$options": "i"}},
                {"product_type": product_name}
            ]
            
            retrieved_docs = []
            for filter_dict in filter_attempts:
                try:
                    retrieved_docs = vector_store.similarity_search(query, k=DEFAULT_SEARCH_K, filter_dict=filter_dict)
                    if retrieved_docs:
                        logger.info(f"Found {len(retrieved_docs)} documents using filter: {filter_dict}")
                        break
                except Exception as e:
                    logger.warning(f"Filter failed: {filter_dict}, error: {e}")
                    continue
            
            # í•„í„°ë§ëœ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
            if not retrieved_docs:
                retrieved_docs = vector_store.similarity_search(query, k=DEFAULT_SEARCH_K)
                logger.info(f"No documents found for product '{product_name}', using general search")
                logger.info(f"General search found {len(retrieved_docs)} documents")
            else:
                logger.info(f"Found {len(retrieved_docs)} documents for product '{product_name}'")
        
        # PDF ì •ë³´ ë¡œê¹…
        if retrieved_docs:
            logger.info("ğŸ“„ [PRODUCT SEARCH] ì‚¬ìš©ëœ PDF ë¬¸ì„œ ì •ë³´:")
            for i, doc in enumerate(retrieved_docs):
                metadata = doc.metadata
                file_name = metadata.get('file_name', 'Unknown')
                page_number = metadata.get('page_number', 'Unknown')
                logger.info(f"  ğŸ“‹ ë¬¸ì„œ {i+1}: {file_name} (í˜ì´ì§€: {page_number})")
        
        # ê³µí†µ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
        response, sources = create_rag_response(slm, query, retrieved_docs)
        
        return {
            **state,
            "response": response,
            "sources": sources,
            "retrieved_docs": retrieved_docs,
            "context_text": format_context(retrieved_docs) if retrieved_docs else "",
            "ready_to_answer": True
        }
        
    except Exception as e:
        logger.error(f"Product search failed: {e}")
        return {
            **state,
            **create_error_response("product_error")
        }

def session_summary_node(state: RAGState, slm: SLM = None) -> RAGState:
    """ì„¸ì…˜ ìš”ì•½ ìƒì„± ë…¸ë“œ (ì²« ëŒ€í™”)"""
    import time
    start_time = time.time()
    logger.info("[SESSION_SUMMARY] Starting session title generation")
    query = state.get("query", "")
    session_context = state.get("session_context")
    conversation_history = state.get("conversation_history", [])
    
    # SLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
    if slm is None:
        slm = SLM()
    
    try:
        # ì²« ëŒ€í™”ì¸ì§€ í™•ì¸
        conversation_history = state.get("conversation_history", [])
        is_first_turn = not conversation_history or len(conversation_history) == 0
        
        if is_first_turn:
            # ê³µí†µ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì œëª© ìƒì„±
            session_title = generate_session_title(query, slm)
            logger.info(f"[SESSION_SUMMARY] Generated title: '{session_title}'")

            # ì„¸ì…˜ì— ì œëª© ì €ì¥
            session_manager.update_session(
                session_context.session_id,
                session_title=session_title
            )
            
            logger.info(f"Session title saved to session: {session_context.session_id}")
            
            # ì—…ë°ì´íŠ¸ëœ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            updated_session_context = session_manager.get_session(session_context.session_id)
            if updated_session_context:
                session_context = updated_session_context
            
            end_time = time.time()
            execution_time = end_time - start_time
            logger.info(f"Returning state with session_title: '{session_title}'")
            logger.info(f"ğŸ“ [NODE] session_summary_node ì™„ë£Œ - ì‹¤í–‰ì‹œê°„: {execution_time:.2f}ì´ˆ")
            return {
                **state,
                "session_title": session_title,
                "ready_to_answer": False,  # RAG ê²€ìƒ‰ì„ ìœ„í•´ Falseë¡œ ì„¤ì •
                "session_context": session_context,  # ì—…ë°ì´íŠ¸ëœ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ í¬í•¨
                "response": ""  # RAG ê²€ìƒ‰ì—ì„œ ì‹¤ì œ ì‘ë‹µ ìƒì„±
            }
        else:
            # ì²« ëŒ€í™”ê°€ ì•„ë‹ˆë©´ ê¸°ì¡´ ì œëª© ì‚¬ìš©í•˜ê³  RAG ê²€ìƒ‰ìœ¼ë¡œ ë„˜ì–´ê°
            existing_title = session_context.session_title if session_context else ""
            end_time = time.time()
            execution_time = end_time - start_time
            logger.info(f"ğŸ“ [NODE] session_summary_node ì™„ë£Œ (ê¸°ì¡´ ì œëª© ì‚¬ìš©) - ì‹¤í–‰ì‹œê°„: {execution_time:.2f}ì´ˆ")
            return {
                **state,
                "session_title": existing_title,
                "ready_to_answer": False,  # RAG ê²€ìƒ‰ì„ ìœ„í•´ Falseë¡œ ì„¤ì •
                "response": ""
            }
            
    except Exception as e:
        logger.error(f"Session summary failed: {e}")
        # í´ë°±: ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©
        fallback_title = generate_session_title(query, slm)
        return {
            **state,
            "session_title": fallback_title,
            "ready_to_answer": False
        }

def rag_search_node(state: RAGState, slm: SLM = None, vector_store=None) -> RAGState:
    """RAG ê²€ìƒ‰ ë…¸ë“œ"""
    import time
    start_time = time.time()
    logger.info("[RAG_SEARCH] Starting document search")
    query = state.get("query", "")
    
    # SLMê³¼ VectorStore ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì¬ì‚¬ìš© ê°€ëŠ¥)
    if slm is None:
        slm = SLM()
    if vector_store is None:
        vector_store = VectorStore()
        vector_store.get_index_ready()  # í•œ ë²ˆë§Œ ì´ˆê¸°í™”
    
    try:
        # ë¬¸ì„œ ê²€ìƒ‰ (ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ê²°ê³¼ ìˆ˜ ì œí•œ)
        retrieved_docs = vector_store.similarity_search(query, k=3)# ë” ì ì€ ê²°ê³¼ë¡œ ì†ë„ í–¥ìƒ
        logger.info(f"[RAG_SEARCH] Found {len(retrieved_docs)} documents")
        
        # ê³µí†µ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
        response, sources = create_rag_response(slm, query, retrieved_docs)
        
        end_time = time.time()
        execution_time = end_time - start_time
        logger.info(f"ğŸ“š [NODE] rag_search_node ì™„ë£Œ - ì‹¤í–‰ì‹œê°„: {execution_time:.2f}ì´ˆ")
        
        return {
            **state,
            "response": response,
            "sources": sources,
            "retrieved_docs": retrieved_docs,
            "context_text": format_context(retrieved_docs) if retrieved_docs else "",
            "ready_to_answer": True
        }
        
    except Exception as e:
        logger.error(f"RAG search failed: {e}")
        return {
            **state,
            **create_error_response("search_error")
        }

def guardrail_check_node(state: RAGState, slm: SLM = None) -> RAGState:
    """ê°€ë“œë ˆì¼ ê²€ì‚¬ ë…¸ë“œ"""
    logger.info("ğŸ›¡ï¸ [NODE] guardrail_check_node ì‹¤í–‰ ì‹œì‘")
    response = state.get("response", "")
    
    # SLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë§¤ê°œë³€ìˆ˜ë¡œ ë°›ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ)
    if slm is None:
        slm = SLM()
    
    try:
        # ê³µí†µ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ë“œë ˆì¼ ê²€ì‚¬
        compliant_response, violations = create_guardrail_response(slm, response)
        
        return {
            **state,
            "guardrail_decision": "COMPLIANT" if not violations else "VIOLATION",
            "violations": violations,
            "compliant_response": compliant_response,
            "response": compliant_response,
            "ready_to_answer": True
        }
        
    except Exception as e:
        logger.error(f"Guardrail check failed: {e}")
        return {
            **state,
            "guardrail_decision": "ERROR",
            "violations": ["ê°€ë“œë ˆì¼ ê²€ì‚¬ ì˜¤ë¥˜"],
            "compliant_response": ERROR_MESSAGES["guardrail_error"],
            "response": ERROR_MESSAGES["guardrail_error"],
            "ready_to_answer": True
        }

def answer_node(state: RAGState) -> RAGState:
    """ìµœì¢… ë‹µë³€ ë…¸ë“œ"""
    import time
    from datetime import datetime
    start_time = time.time()
    logger.info("[ANSWER] Preparing final response")
    response = state.get("response", "")
    
    if not response or not response.strip():
        # ê¸°ë³¸ ì‘ë‹µ ìƒì„± (RAG ê²€ìƒ‰ì´ ì‹¤íŒ¨í•œ ê²½ìš°ì—ë§Œ)
        response = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì‹œê±°ë‚˜ ê´€ë ¨ ë¶€ì„œì— ë¬¸ì˜í•´ì£¼ì„¸ìš”."
        logger.info("[ANSWER] Using default response")
    
    # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì œê±°
    response = clean_markdown_formatting(response)
    
    # ëŒ€í™” í„´ ì €ì¥
    session_context = state.get("session_context")
    if session_context:
        from .session_manager import ConversationTurn
        turn = ConversationTurn(
            turn_id=state.get("turn_id", ""),
            timestamp=datetime.now(),
            user_query=state.get("query", ""),
            ai_response=response,
            category=state.get("intent_category", ""),
            product_name=state.get("product_name", ""),
            sources=state.get("sources", []),
            session_context={}  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”
        )
        session_manager.add_conversation_turn(session_context.session_id, turn)
        logger.info(f"âœ… [NODE] ëŒ€í™” í„´ ì €ì¥ ì™„ë£Œ: {session_context.session_id}")
    
    end_time = time.time()
    execution_time = end_time - start_time
    logger.info(f"âœ… [NODE] answer_node ì™„ë£Œ - ì‹¤í–‰ì‹œê°„: {execution_time:.2f}ì´ˆ")
    
    return {
        **state,
        "response": response,
        "ready_to_answer": True
    }

